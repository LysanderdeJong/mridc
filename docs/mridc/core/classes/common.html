<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 10.0.1"/>
    <title>mridc.core.classes.common API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;}nav.pdoc{--pad:1.75rem;--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent }nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc li{display:block;margin:0;padding:.2rem 0 .2rem var(--indent);transition:all 100ms;}nav.pdoc > div > ul > li{padding-left:0;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--code);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.pdoc details{filter:opacity(1);}.pdoc details:not([open]){height:0;}.pdoc details > summary{position:absolute;top:-35px;right:0;font-size:.75rem;color:var(--muted);padding:0 .7em;user-select:none;cursor:pointer;}.pdoc details > summary:focus{outline:0;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc > section:first-of-type > .docstring{margin-bottom:2.5rem;}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc .headerlink{position:absolute;width:0;margin-left:-1.5rem;line-height:1.4rem;font-size:1.5rem;font-weight:normal;transition:all 100ms ease-in-out;opacity:0;user-select:none;}.pdoc .attr > .headerlink{margin-left:-2.5rem;}.pdoc *:hover > .headerlink,.pdoc *:target > .attr > .headerlink{opacity:1;}.pdoc .attr{display:block;color:var(--text);margin:.5rem 0 .5rem;padding:.4rem 5rem .4rem 1rem;background-color:var(--accent);}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{white-space:pre-wrap;}.pdoc .annotation{color:var(--annotation);}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../classes.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;mridc.core.classes</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



        <h2>API Documentation</h2>
            <ul class="memberlist">
            <li>
                    <a class="class" href="#Typing">Typing</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Typing.__init__">Typing</a>
                        </li>
                        <li>
                                <a class="variable" href="#Typing.input_types">input_types</a>
                        </li>
                        <li>
                                <a class="variable" href="#Typing.output_types">output_types</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#FileIO">FileIO</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#FileIO.__init__">FileIO</a>
                        </li>
                        <li>
                                <a class="function" href="#FileIO.save_to">save_to</a>
                        </li>
                        <li>
                                <a class="function" href="#FileIO.restore_from">restore_from</a>
                        </li>
                        <li>
                                <a class="function" href="#FileIO.from_config_file">from_config_file</a>
                        </li>
                        <li>
                                <a class="function" href="#FileIO.to_config_file">to_config_file</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#Model">Model</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Model.__init__">Model</a>
                        </li>
                        <li>
                                <a class="function" href="#Model.list_available_models">list_available_models</a>
                        </li>
                        <li>
                                <a class="function" href="#Model.get_available_model_names">get_available_model_names</a>
                        </li>
                        <li>
                                <a class="function" href="#Model.from_pretrained">from_pretrained</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#PretrainedModelInfo">PretrainedModelInfo</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#PretrainedModelInfo.__init__">PretrainedModelInfo</a>
                        </li>
                        <li>
                                <a class="variable" href="#PretrainedModelInfo.class_">class_</a>
                        </li>
                        <li>
                                <a class="variable" href="#PretrainedModelInfo.aliases">aliases</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#Serialization">Serialization</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Serialization.__init__">Serialization</a>
                        </li>
                        <li>
                                <a class="function" href="#Serialization.from_config_dict">from_config_dict</a>
                        </li>
                        <li>
                                <a class="function" href="#Serialization.to_config_dict">to_config_dict</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="function" href="#is_typecheck_enabled">is_typecheck_enabled</a>
            </li>
            <li>
                    <a class="class" href="#typecheck">typecheck</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#typecheck.__init__">typecheck</a>
                        </li>
                        <li>
                                <a class="class" href="#typecheck.TypeState">typecheck.TypeState</a>
                                        <ul class="memberlist">
                                    <li>
                                            <a class="variable" href="#typecheck.TypeState.UNINITIALIZED">UNINITIALIZED</a>
                                    </li>
                            </ul>

                        </li>
                        <li>
                                <a class="function" href="#typecheck.set_typecheck_enabled">set_typecheck_enabled</a>
                        </li>
                        <li>
                                <a class="function" href="#typecheck.disable_checks">disable_checks</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section>
                    <h1 class="modulename">
<a href="./../../../mridc.html">mridc</a><wbr>.<a href="./../../core.html">core</a><wbr>.<a href="./../classes.html">classes</a><wbr>.common    </h1>


                        <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span><span class="c1"># encoding: utf-8</span>
<span class="n">__author__</span> <span class="o">=</span> <span class="s2">&quot;Dimitrios Karkalousos&quot;</span>

<span class="c1"># Interfaces common to all Neural Modules and Models.</span>
<span class="kn">import</span> <span class="nn">hashlib</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">contextmanager</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">total_ordering</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="c1"># Taken and adapted from: https://github.com/NVIDIA/NeMo/blob/main/nemo/core/classes/common.py</span>
<span class="kn">import</span> <span class="nn">hydra</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">wrapt</span>
<span class="kn">from</span> <span class="nn">omegaconf</span> <span class="kn">import</span> <span class="n">DictConfig</span><span class="p">,</span> <span class="n">OmegaConf</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning</span> <span class="kn">import</span> <span class="n">Trainer</span>

<span class="kn">import</span> <span class="nn">mridc.utils</span>
<span class="kn">from</span> <span class="nn">mridc.core.connectors.save_restore_connector</span> <span class="kn">import</span> <span class="n">SaveRestoreConnector</span>
<span class="kn">from</span> <span class="nn">mridc.core.neural_types.comparison</span> <span class="kn">import</span> <span class="n">NeuralTypeComparisonResult</span>
<span class="kn">from</span> <span class="nn">mridc.core.neural_types.neural_type</span> <span class="kn">import</span> <span class="n">NeuralType</span>
<span class="kn">from</span> <span class="nn">mridc.utils</span> <span class="kn">import</span> <span class="n">logging</span>
<span class="kn">from</span> <span class="nn">mridc.utils.cloud</span> <span class="kn">import</span> <span class="n">maybe_download_from_cloud</span>

<span class="n">_HAS_HYDRA</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Typing&quot;</span><span class="p">,</span> <span class="s2">&quot;FileIO&quot;</span><span class="p">,</span> <span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="s2">&quot;PretrainedModelInfo&quot;</span><span class="p">,</span> <span class="s2">&quot;Serialization&quot;</span><span class="p">,</span> <span class="s2">&quot;is_typecheck_enabled&quot;</span><span class="p">,</span> <span class="s2">&quot;typecheck&quot;</span><span class="p">]</span>

<span class="n">_TYPECHECK_ENABLED</span> <span class="o">=</span> <span class="kc">True</span>


<span class="k">def</span> <span class="nf">is_typecheck_enabled</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Getter method for typechecking state.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_TYPECHECK_ENABLED</span>


<span class="nd">@dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TypecheckMetadata</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Metadata class for input/output neural types.</span>
<span class="sd">    # Primary attributes</span>
<span class="sd">    original_types: Preserve the dictionary of type information provided.</span>
<span class="sd">    ignore_collections: For backward compatibility, container support can be disabled explicitly</span>
<span class="sd">        using this flag. When set to True, all nesting is ignored and nest-depth checks are skipped.</span>
<span class="sd">    # Derived attributed</span>
<span class="sd">    mandatory_types: Sub-dictionary of `original_types` which contains only those types which</span>
<span class="sd">        are mandatory to include when calling the function.</span>
<span class="sd">    base_types: Dictionary of flattened `str: NeuralType` definitions, disregarding the nest level</span>
<span class="sd">        details into appropriate arguments.</span>
<span class="sd">    container_depth: Dictionary mapping `str: int` - such that the valid depth of the nest of this</span>
<span class="sd">        neural type is recorded.</span>
<span class="sd">    has_container_types: Bool flag declaring if any of the neural types declares a container nest</span>
<span class="sd">        in its signature.</span>
<span class="sd">    is_singular_container_type: Bool flag declaring if this is a single Neural Type with a container</span>
<span class="sd">        nest in its signature. Required for supporting python list expansion in return statement.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">original_types</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]</span>
    <span class="n">ignore_collections</span><span class="p">:</span> <span class="nb">bool</span>

    <span class="n">mandatory_types</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">base_types</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">container_depth</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">has_container_types</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">is_singular_container_type</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">has_container_types</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">type_val</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="k">for</span> <span class="n">type_val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_types</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">has_container_types</span> <span class="o">=</span> <span class="n">has_container_types</span>

        <span class="c1"># If only one NeuralType is declared, and it declares a container nest, set to True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_singular_container_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_container_types</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">original_types</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>

        <span class="c1"># If container nests are declared, flatten the nest into `base_types`</span>
        <span class="c1"># Also compute the nest depth for each of the NeuralTypes</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_container_types</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_types</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">container_depth</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="k">for</span> <span class="n">type_key</span><span class="p">,</span> <span class="n">type_val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_types</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">depth</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">while</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">type_val</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">type_val</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Neural Type `</span><span class="si">{</span><span class="n">type_key</span><span class="si">}</span><span class="s2">`: </span><span class="si">{</span><span class="n">type_val</span><span class="si">}</span><span class="s2"> definition contains more than one element when&quot;</span>
                            <span class="s2">&quot;declaring the nested container structure.</span><span class="se">\n</span><span class="s2">&quot;</span>
                            <span class="s2">&quot;Please ensure that you have only 1 NeuralType inside of the entire nested structure &quot;</span>
                            <span class="s2">&quot;definition.&quot;</span>
                        <span class="p">)</span>

                    <span class="n">type_val</span> <span class="o">=</span> <span class="n">type_val</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">depth</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">type_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">type_val</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">container_depth</span><span class="p">[</span><span class="n">type_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">depth</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Otherwise, simply preserve the original_types and set depth of nest to 0.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_types</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_types</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">container_depth</span> <span class="o">=</span> <span class="p">{</span><span class="n">type_key</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">type_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_types</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>

        <span class="c1"># Compute subset of original_types which are mandatory in the call argspec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mandatory_types</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">type_key</span><span class="p">:</span> <span class="n">type_val</span> <span class="k">for</span> <span class="n">type_key</span><span class="p">,</span> <span class="n">type_val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_types</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">type_val</span><span class="o">.</span><span class="n">optional</span>
        <span class="p">}</span>


<span class="k">class</span> <span class="nc">Typing</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;An interface which endows module with neural types&quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_types</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Define these to enable input neural type checks&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output_types</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Define these to enable output neural type checks&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_validate_input_types</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_types</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_collections</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function does a few things.</span>
<span class="sd">        1) It ensures that len(self.input_types &lt;non-optional&gt;) &lt;= len(kwargs) &lt;= len(self.input_types).</span>
<span class="sd">        2) For each (keyword name, keyword value) passed as input to the wrapped function:</span>
<span class="sd">            - Check if the keyword name exists in the list of valid self.input_types names.</span>
<span class="sd">            - Check if keyword value has the `neural_type` property.</span>
<span class="sd">                - If it does, then perform a comparative check and assert that neural types</span>
<span class="sd">                    are compatible (SAME or GREATER).</span>
<span class="sd">            - Check if keyword value is a container type (list or tuple). If yes,</span>
<span class="sd">                then perform the elementwise test of neural type above on each element</span>
<span class="sd">                of the nested structure, recursively.</span>
<span class="sd">        Args:</span>
<span class="sd">            input_types: Either the `input_types` defined at class level, or the local function</span>
<span class="sd">                overridden type definition.</span>
<span class="sd">            ignore_collections: For backward compatibility, container support can be disabled explicitly</span>
<span class="sd">                using this flag. When set to True, all nesting is ignored and nest-depth checks are skipped.</span>
<span class="sd">            kwargs: Dictionary of argument_name:argument_value pairs passed to the wrapped</span>
<span class="sd">                function upon call.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: Properly implement this</span>
        <span class="k">if</span> <span class="n">input_types</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="c1"># Precompute metadata</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="n">TypecheckMetadata</span><span class="p">(</span><span class="n">original_types</span><span class="o">=</span><span class="n">input_types</span><span class="p">,</span> <span class="n">ignore_collections</span><span class="o">=</span><span class="n">ignore_collections</span><span class="p">)</span>

        <span class="n">total_input_types</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_types</span><span class="p">)</span>
        <span class="n">mandatory_input_types</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">mandatory_types</span><span class="p">)</span>

        <span class="c1"># Allow number of input arguments to be &lt;= total input neural types.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">mandatory_input_types</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">total_input_types</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Number of input arguments provided (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span><span class="si">}</span><span class="s2">) is not as expected. Function has &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">total_input_types</span><span class="si">}</span><span class="s2"> total inputs with </span><span class="si">{</span><span class="n">mandatory_input_types</span><span class="si">}</span><span class="s2"> mandatory inputs.&quot;</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># Check if keys exists in the defined input types</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">input_types</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Input argument </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> has no corresponding input_type match. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Existing input_types = </span><span class="si">{</span><span class="n">input_types</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

                <span class="c1"># Perform neural type check</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;neural_type&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">compare</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">neural_type</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="n">NeuralTypeComparisonResult</span><span class="o">.</span><span class="n">SAME</span><span class="p">,</span>
                <span class="n">NeuralTypeComparisonResult</span><span class="o">.</span><span class="n">GREATER</span><span class="p">,</span>
            <span class="p">):</span>
                <span class="n">error_msg</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">input_types</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">compare</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">neural_type</span><span class="p">)</span><span class="si">}</span><span class="s2"> :&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;Input type expected : </span><span class="si">{</span><span class="n">input_types</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;Input type found : </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">neural_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;Argument: </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="p">]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dict_tuple</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">elements_type</span><span class="o">.</span><span class="n">type_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
                    <span class="n">error_msg</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;  input param_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> : </span><span class="si">{</span><span class="n">dict_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">dict_tuple</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">error_msg</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;  input param_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> : </span><span class="si">{</span><span class="n">dict_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">dict_tuple</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dict_tuple</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">neural_type</span><span class="o">.</span><span class="n">elements_type</span><span class="o">.</span><span class="n">type_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
                <span class="p">)</span>

                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">error_msg</span><span class="p">))</span>

                <span class="c1"># Perform input n dim check</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">):</span>
                <span class="n">value_shape</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">type_shape</span> <span class="o">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">axes</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">key</span>

                <span class="k">if</span> <span class="n">type_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">type_shape</span><span class="p">)):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Input shape mismatch occurred for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> in module </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> : </span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Input shape expected = </span><span class="si">{</span><span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">axes</span><span class="si">}</span><span class="s2"> | </span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Input shape found : </span><span class="si">{</span><span class="n">value_shape</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">:</span>
                    <span class="c1"># This initiates a DFS, tracking the depth count as it goes along the nested structure.</span>
                    <span class="c1"># Initial depth is 1 as we consider the current loop to be the 1st step inside the nest.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__check_neural_type</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_attach_and_validate_output_types</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out_objects</span><span class="p">,</span> <span class="n">ignore_collections</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">output_types</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function does a few things.</span>
<span class="sd">        1) It ensures that len(out_object) == len(self.output_types).</span>
<span class="sd">        2) If the output is a tensor (or list/tuple of list/tuple ... of tensors), it</span>
<span class="sd">            attaches a neural_type to it. For objects without the neural_type attribute,</span>
<span class="sd">            such as python objects (dictionaries and lists, primitive data types, structs),</span>
<span class="sd">            no neural_type is attached.</span>
<span class="sd">            Note: tensor.neural_type is only checked during _validate_input_types which is</span>
<span class="sd">            called prior to forward().</span>
<span class="sd">        Args:</span>
<span class="sd">            output_types: Either the `output_types` defined at class level, or the local function</span>
<span class="sd">                overridden type definition.</span>
<span class="sd">            ignore_collections: For backward compatibility, container support can be disabled explicitly</span>
<span class="sd">                using this flag. When set to True, all nesting is ignored and nest-depth checks are skipped.</span>
<span class="sd">            out_objects: The outputs of the wrapped function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: Properly implement this</span>
        <span class="k">if</span> <span class="n">output_types</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="c1"># Precompute metadata</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="n">TypecheckMetadata</span><span class="p">(</span><span class="n">original_types</span><span class="o">=</span><span class="n">output_types</span><span class="p">,</span> <span class="n">ignore_collections</span><span class="o">=</span><span class="n">ignore_collections</span><span class="p">)</span>
        <span class="n">out_types_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="n">mandatory_out_types_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">mandatory_types</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

        <span class="c1"># First convert all outputs to list/tuple format to check correct number of outputs</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">out_objects</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">out_container</span> <span class="o">=</span> <span class="n">out_objects</span>  <span class="c1"># can be any rank nested structure</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out_container</span> <span class="o">=</span> <span class="p">[</span><span class="n">out_objects</span><span class="p">]</span>

        <span class="c1"># If this neural type has a *single output*, with *support for nested outputs*,</span>
        <span class="c1"># then *do not* perform any check on the number of output items against the number</span>
        <span class="c1"># of neural types (in this case, 1).</span>
        <span class="c1"># This is done as python will *not* wrap a single returned list into a tuple of length 1,</span>
        <span class="c1"># instead opting to keep the list intact. Therefore len(out_container) in such a case</span>
        <span class="c1"># is the length of all the elements of that list - each of which has the same corresponding</span>
        <span class="c1"># neural type (defined as the singular container type).</span>
        <span class="k">if</span> <span class="n">metadata</span><span class="o">.</span><span class="n">is_singular_container_type</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="c1"># In all other cases, python will wrap multiple outputs into an outer tuple.</span>
        <span class="c1"># Allow number of output arguments to be &lt;= total output neural types and &gt;= mandatory outputs.</span>

        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_container</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_types_list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_container</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">mandatory_out_types_list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;Number of output arguments provided (</span><span class="si">{}</span><span class="s2">) is not as expected. It should be larger than </span><span class="si">{}</span><span class="s2"> and &quot;</span>
                <span class="s2">&quot;less than </span><span class="si">{}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;This can be either because insufficient/extra number of output NeuralTypes were provided,&quot;</span>
                <span class="s2">&quot;or the provided NeuralTypes </span><span class="si">{}</span><span class="s2"> should enable container support &quot;</span>
                <span class="s2">&quot;(add &#39;[]&#39; to the NeuralType definition)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">out_container</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_types_list</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">mandatory_out_types_list</span><span class="p">),</span> <span class="n">output_types</span>
                <span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># Attach types recursively, if possible</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out_objects</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out_objects</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="c1"># Here, out_objects is a single object which can potentially be attached with a NeuralType</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">out_objects</span><span class="o">.</span><span class="n">neural_type</span> <span class="o">=</span> <span class="n">out_types_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="k">pass</span>

                <span class="c1"># Perform output n dim check</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">out_objects</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">):</span>
                <span class="n">value_shape</span> <span class="o">=</span> <span class="n">out_objects</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">type_shape</span> <span class="o">=</span> <span class="n">out_types_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axes</span>
                <span class="k">if</span> <span class="n">type_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">type_shape</span><span class="p">):</span>
                    <span class="n">name</span> <span class="o">=</span> <span class="n">out_types_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Output shape mismatch occurred for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> in module </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> : </span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Output shape expected = </span><span class="si">{</span><span class="n">type_shape</span><span class="si">}</span><span class="s2"> | </span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Output shape found : </span><span class="si">{</span><span class="n">value_shape</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

        <span class="k">elif</span> <span class="n">metadata</span><span class="o">.</span><span class="n">is_singular_container_type</span><span class="p">:</span>
            <span class="c1"># If only a single neural type is provided, and it defines a container nest,</span>
            <span class="c1"># then all elements of the returned list/tuple are assumed to belong to that</span>
            <span class="c1"># singular neural type.</span>
            <span class="c1"># As such, the &quot;current&quot; depth inside the DFS loop is counted as 1,</span>
            <span class="c1"># and subsequent nesting will increase this count.</span>

            <span class="c1"># NOTE:</span>
            <span class="c1"># As the flag `is_singular_container_type` will activate only for</span>
            <span class="c1"># the case where there is 1 output type defined with container nesting,</span>
            <span class="c1"># this is a safe assumption to make.</span>
            <span class="n">depth</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="c1"># NOTE:</span>
            <span class="c1"># A user may chose to explicitly wrap the single output list within an explicit tuple</span>
            <span class="c1"># In such a case we reduce the &quot;current&quot; depth to 0 - to acknowledge the fact that</span>
            <span class="c1"># the actual nest exists within a wrapper tuple.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_objects</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">out_objects</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">tuple</span><span class="p">:</span>
                <span class="n">depth</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">out_objects</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__attach_neural_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">out_types_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If more then one item is returned in a return statement, python will wrap</span>
            <span class="c1"># the output with an outer tuple. Therefore there must be a 1:1 correspondence</span>
            <span class="c1"># of the output_neural type (with or without nested structure) to the actual output</span>
            <span class="c1"># (whether it is a single object or a nested structure of objects).</span>
            <span class="c1"># Therefore in such a case, we &quot;start&quot; the DFS at depth 0 - since the recursion is</span>
            <span class="c1"># being applied on 1 neural type : 1 output struct (single or nested output).</span>
            <span class="c1"># Since we are guaranteed that the outer tuple will be built by python,</span>
            <span class="c1"># assuming initial depth of 0 is appropriate.</span>
            <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">res</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">out_objects</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__attach_neural_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">out_types_list</span><span class="p">[</span><span class="n">ind</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">__check_neural_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Checks if the object is of the correct type, and attaches the correct NeuralType.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__check_neural_type</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
            <span class="k">return</span>  <span class="c1"># after processing nest, return to avoid testing nest itself</span>

        <span class="n">type_val</span> <span class="o">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

        <span class="c1"># If nest depth doesnt match neural type structure depth, raise an error</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">metadata</span><span class="o">.</span><span class="n">ignore_collections</span> <span class="ow">and</span> <span class="n">depth</span> <span class="o">!=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">container_depth</span><span class="p">[</span><span class="n">name</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;While checking input neural types,</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;Nested depth of value did not match container specification:</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Current nested depth of NeuralType &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; (</span><span class="si">{</span><span class="n">type_val</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">depth</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Expected nested depth : </span><span class="si">{</span><span class="n">metadata</span><span class="o">.</span><span class="n">container_depth</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;neural_type&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">type_val</span><span class="o">.</span><span class="n">compare</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">neural_type</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span>
            <span class="n">NeuralTypeComparisonResult</span><span class="o">.</span><span class="n">SAME</span><span class="p">,</span>
            <span class="n">NeuralTypeComparisonResult</span><span class="o">.</span><span class="n">GREATER</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">type_val</span><span class="o">.</span><span class="n">compare</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">neural_type</span><span class="p">)</span><span class="si">}</span><span class="s2"> : </span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Input type expected = </span><span class="si">{</span><span class="n">type_val</span><span class="si">}</span><span class="s2"> | </span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Input type found : </span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="n">neural_type</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Perform input n dim check</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">):</span>
            <span class="n">value_shape</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">type_shape</span> <span class="o">=</span> <span class="n">type_val</span><span class="o">.</span><span class="n">axes</span>

            <span class="k">if</span> <span class="n">type_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">type_shape</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Input shape mismatch occurred for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> in module </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> : </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Input shape expected = </span><span class="si">{</span><span class="n">type_shape</span><span class="si">}</span><span class="s2"> | </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Input shape found : </span><span class="si">{</span><span class="n">value_shape</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__attach_neural_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Attach NeuralType to the object.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__attach_neural_type</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
            <span class="k">return</span>  <span class="c1"># after processing nest, return to avoid argument insertion into nest itself</span>

        <span class="n">type_val</span> <span class="o">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

        <span class="c1"># If nest depth doesnt match neural type structure depth, raise an error</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">metadata</span><span class="o">.</span><span class="n">ignore_collections</span> <span class="ow">and</span> <span class="n">depth</span> <span class="o">!=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">container_depth</span><span class="p">[</span><span class="n">name</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;While attaching output neural types,</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;Nested depth of value did not match container specification:</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Current nested depth of NeuralType &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; (</span><span class="si">{</span><span class="n">type_val</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">depth</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Expected nested depth : </span><span class="si">{</span><span class="n">metadata</span><span class="o">.</span><span class="n">container_depth</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">obj</span><span class="o">.</span><span class="n">neural_type</span> <span class="o">=</span> <span class="n">type_val</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="c1"># Perform output n dim check</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">):</span>
            <span class="n">value_shape</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">type_shape</span> <span class="o">=</span> <span class="n">type_val</span><span class="o">.</span><span class="n">axes</span>

            <span class="k">if</span> <span class="n">type_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">type_shape</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Output shape mismatch occurred for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> in module </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> : </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Output shape expected = </span><span class="si">{</span><span class="n">type_shape</span><span class="si">}</span><span class="s2"> | </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Output shape found : </span><span class="si">{</span><span class="n">value_shape</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>


<span class="k">class</span> <span class="nc">Serialization</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for serialization.&quot;&quot;&quot;</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_config_dict</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="s2">&quot;DictConfig&quot;</span><span class="p">,</span> <span class="n">trainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Trainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiates object using DictConfig-based configuration&quot;&quot;&quot;</span>
        <span class="c1"># Resolve the config dict</span>
        <span class="k">if</span> <span class="n">_HAS_HYDRA</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">DictConfig</span><span class="p">):</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
                <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

            <span class="n">config</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">maybe_update_config_version</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

        <span class="c1"># Hydra 0.x API</span>
        <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;cls&quot;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">or</span> <span class="s2">&quot;target&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;params&quot;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">and</span> <span class="n">_HAS_HYDRA</span><span class="p">:</span>
            <span class="c1"># regular hydra-based instantiation</span>
            <span class="n">instance</span> <span class="o">=</span> <span class="n">hydra</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">instantiate</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
        <span class="c1"># Hydra 1.x API</span>
        <span class="k">elif</span> <span class="s2">&quot;_target_&quot;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">and</span> <span class="n">_HAS_HYDRA</span><span class="p">:</span>
            <span class="c1"># regular hydra-based instantiation</span>
            <span class="n">instance</span> <span class="o">=</span> <span class="n">hydra</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">instantiate</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">instance</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">imported_cls_tb</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">instance_init_error</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="c1"># Attempt class path resolution from config `target` class (if it exists)</span>
            <span class="k">if</span> <span class="s2">&quot;target&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="n">target_cls</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>  <span class="c1"># No guarantee that this is a omegaconf class</span>
                <span class="n">imported_cls</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># try to import the target class</span>
                    <span class="n">imported_cls</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">import_class_by_path</span><span class="p">(</span><span class="n">target_cls</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                    <span class="n">imported_cls_tb</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>

                <span class="c1"># try instantiating model with target class</span>
                <span class="k">if</span> <span class="n">imported_cls</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># if calling class (cls) is subclass of imported class,</span>
                    <span class="c1"># use subclass instead</span>
                    <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">imported_cls</span><span class="p">):</span>
                        <span class="n">imported_cls</span> <span class="o">=</span> <span class="bp">cls</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">accepts_trainer</span> <span class="o">=</span> <span class="n">Serialization</span><span class="o">.</span><span class="n">_inspect_signature_for_trainer</span><span class="p">(</span><span class="n">imported_cls</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">accepts_trainer</span><span class="p">:</span>
                            <span class="n">instance</span> <span class="o">=</span> <span class="n">imported_cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">instance</span> <span class="o">=</span> <span class="n">imported_cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="n">imported_cls_tb</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
                        <span class="n">instance_init_error</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                        <span class="n">instance</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># target class resolution was unsuccessful, fall back to current `cls`</span>
            <span class="k">if</span> <span class="n">instance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">imported_cls_tb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Model instantiation from target class </span><span class="si">{</span><span class="n">target_cls</span><span class="si">}</span><span class="s2"> failed with following error.</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Falling back to `cls`.</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">imported_cls_tb</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="n">accepts_trainer</span> <span class="o">=</span> <span class="n">Serialization</span><span class="o">.</span><span class="n">_inspect_signature_for_trainer</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">accepts_trainer</span><span class="p">:</span>
                        <span class="n">instance</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">instance</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">imported_cls_tb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Instance failed restore_from due to: </span><span class="si">{</span><span class="n">instance_init_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">imported_cls_tb</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="n">e</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="s2">&quot;_cfg&quot;</span><span class="p">):</span>
            <span class="n">instance</span><span class="o">.</span><span class="n">_cfg</span> <span class="o">=</span> <span class="n">config</span>
        <span class="k">return</span> <span class="n">instance</span>

    <span class="k">def</span> <span class="nf">to_config_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;DictConfig&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns object&#39;s configuration to config dictionary&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cfg&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
            <span class="c1"># Resolve the config dict</span>
            <span class="k">if</span> <span class="n">_HAS_HYDRA</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">,</span> <span class="n">DictConfig</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
                <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

                <span class="n">config</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">maybe_update_config_version</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="o">=</span> <span class="n">config</span>

            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;to_config_dict() can currently only return object._cfg but current object does not have it.&quot;</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_inspect_signature_for_trainer</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">check_cls</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Inspects the signature of the class to see if it accepts a trainer argument.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">check_cls</span><span class="p">,</span> <span class="s2">&quot;__init__&quot;</span><span class="p">):</span>
            <span class="n">signature</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">check_cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">Trainer</span> <span class="ow">in</span> <span class="n">signature</span><span class="o">.</span><span class="n">parameters</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="k">class</span> <span class="nc">FileIO</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for file IO.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">save_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Saves module/model with weights&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">restore_from</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">restore_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">override_config_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">map_location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">return_config</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">trainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Trainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">save_restore_connector</span><span class="p">:</span> <span class="n">SaveRestoreConnector</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Restores module/model with weights&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_config_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">path2yaml_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiates an instance of mridc Model from YAML config file.</span>
<span class="sd">        Weights will be initialized randomly.</span>
<span class="sd">        Args:</span>
<span class="sd">            path2yaml_file: path to yaml file with model configuration</span>
<span class="sd">        Returns:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">Serialization</span><span class="p">):</span>
            <span class="n">conf</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path2yaml_file</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_config_dict</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">to_config_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path2yaml_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves current instance&#39;s configuration to YAML config file. Weights will not be saved.</span>
<span class="sd">        Args:</span>
<span class="sd">            path2yaml_file: path2yaml_file: path to yaml file where model model configuration will be saved</span>
<span class="sd">        Returns:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cfg&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">maybe_update_config_version</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path2yaml_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fout</span><span class="p">:</span>
                <span class="n">OmegaConf</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">fout</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>


<span class="nd">@total_ordering</span>
<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">PretrainedModelInfo</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Class to store information about a pretrained model.&quot;&quot;&quot;</span>

    <span class="n">pretrained_model_name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">description</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">location</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">class_</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">aliases</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">base</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="n">extras</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;pretrained_model_name=</span><span class="si">{pretrained_model_name}</span><span class="s2">,</span><span class="se">\n\t</span><span class="s2">&quot;</span>
            <span class="s2">&quot;description=</span><span class="si">{description}</span><span class="s2">,</span><span class="se">\n\t</span><span class="s2">&quot;</span>
            <span class="s2">&quot;location=</span><span class="si">{location}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extras</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{extras}</span><span class="s2">,</span><span class="se">\n\t</span><span class="s2">&quot;</span> <span class="s2">&quot;class_=</span><span class="si">{class_}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">extras</span><span class="o">=</span><span class="n">extras</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>

        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">base</span><span class="si">}</span><span class="s2">(</span><span class="se">\n\t</span><span class="si">{</span><span class="n">extras</span><span class="si">}</span><span class="se">\n</span><span class="s2">)&quot;</span>

    <span class="k">def</span> <span class="fm">__hash__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">hash</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">location</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="c1"># another object is equal to self, iff</span>
        <span class="c1"># if it&#39;s hash is equal to hash(self)</span>
        <span class="k">return</span> <span class="nb">hash</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="nb">hash</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">pretrained_model_name</span>

    <span class="k">def</span> <span class="fm">__lt__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="o">&lt;</span> <span class="n">other</span><span class="o">.</span><span class="n">pretrained_model_name</span>


<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">Typing</span><span class="p">,</span> <span class="n">Serialization</span><span class="p">,</span> <span class="n">FileIO</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
    <span class="sd">&quot;&quot;&quot;Abstract class offering interface which should be implemented by all mridc models.&quot;&quot;&quot;</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">list_available_models</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PretrainedModelInfo</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Should list all pre-trained models available.</span>
<span class="sd">        Note: There is no check that requires model names and aliases to be unique. In the case of a collision,</span>
<span class="sd">        whatever model (or alias) is listed first in the this returned list will be instantiated.</span>
<span class="sd">        Returns:</span>
<span class="sd">            A list of PretrainedModelInfo entries</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">get_available_model_names</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the list of model names available.</span>
<span class="sd">        to get the complete model description use list_available_models()</span>
<span class="sd">        Returns:</span>
<span class="sd">            A list of model names</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">()]</span>  <span class="c1"># type: ignore</span>
            <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="p">[]</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">refresh_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">override_config_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">map_location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">return_config</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">trainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Trainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">save_restore_connector</span><span class="p">:</span> <span class="n">SaveRestoreConnector</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiates an instance of mridc</span>
<span class="sd">        Use restore_from() to instantiate from a local .mridc file.</span>
<span class="sd">        Args:</span>
<span class="sd">            model_name: string key which will be used to find the module.</span>
<span class="sd">            refresh_cache: If set to True, then when fetching from cloud, this will re-fetch the file</span>
<span class="sd">                from cloud even if it is already found in a cache locally.</span>
<span class="sd">            override_config_path: path to a yaml config that will override the internal</span>
<span class="sd">                config file</span>
<span class="sd">            map_location: Optional torch.device() to map the instantiated model to a device.</span>
<span class="sd">                By default (None), it will select a GPU if available, falling back to CPU otherwise.</span>
<span class="sd">            strict: Passed to torch.load_state_dict. By default true.</span>
<span class="sd">            return_config: If set to true, will return just the underlying config of the restored</span>
<span class="sd">                model as an OmegaConf DictConfig object without instantiating the model.</span>
<span class="sd">            trainer: Optional Trainer object to use for restoring the model.</span>
<span class="sd">            save_restore_connector: Optional SaveRestoreConnector object to use for restoring the model.</span>
<span class="sd">        Returns:</span>
<span class="sd">            A model instance of a particular model class or its underlying config (if return_config is set).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">save_restore_connector</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">save_restore_connector</span> <span class="o">=</span> <span class="n">SaveRestoreConnector</span><span class="p">()</span>

        <span class="n">location_in_the_cloud</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">description</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">models</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">pretrained_model_info</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">():</span>  <span class="c1"># type: ignore</span>
                <span class="n">found</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">if</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="o">==</span> <span class="n">model_name</span><span class="p">:</span>
                    <span class="n">found</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">elif</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">aliases</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">alias</span> <span class="ow">in</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">aliases</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">alias</span> <span class="o">==</span> <span class="n">model_name</span><span class="p">:</span>
                            <span class="n">found</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="k">break</span>
                <span class="k">if</span> <span class="n">found</span><span class="p">:</span>
                    <span class="n">location_in_the_cloud</span> <span class="o">=</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">location</span>
                    <span class="n">description</span> <span class="o">=</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">description</span>
                    <span class="n">class_</span> <span class="o">=</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">class_</span>
                    <span class="k">break</span>

        <span class="k">if</span> <span class="n">location_in_the_cloud</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> was not found. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Check cls.list_available_models() for the list of all available models.&quot;</span>
            <span class="p">)</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">location_in_the_cloud</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">url</span> <span class="o">=</span> <span class="n">location_in_the_cloud</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">resolve_cache_dir</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename</span><span class="p">[:</span><span class="o">-</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="c1"># If either description and location in the cloud changes, this will force re-download</span>
        <span class="c1"># of the model.</span>
        <span class="n">cache_subfolder</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">sha512</span><span class="p">((</span><span class="n">location_in_the_cloud</span> <span class="o">+</span> <span class="n">description</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>
        <span class="c1"># if file exists on cache_folder/subfolder, it will be re-used, unless refresh_cache is True</span>
        <span class="n">mridc_model_file_in_cache</span> <span class="o">=</span> <span class="n">maybe_download_from_cloud</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span> <span class="n">subfolder</span><span class="o">=</span><span class="n">cache_subfolder</span><span class="p">,</span> <span class="n">refresh_cache</span><span class="o">=</span><span class="n">refresh_cache</span>
        <span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Instantiating model from pre-trained checkpoint&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">class_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">class_</span> <span class="o">=</span> <span class="bp">cls</span>

        <span class="k">return</span> <span class="n">class_</span><span class="o">.</span><span class="n">restore_from</span><span class="p">(</span>
            <span class="n">restore_path</span><span class="o">=</span><span class="n">mridc_model_file_in_cache</span><span class="p">,</span>
            <span class="n">override_config_path</span><span class="o">=</span><span class="n">override_config_path</span><span class="p">,</span>
            <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">,</span>
            <span class="n">strict</span><span class="o">=</span><span class="n">strict</span><span class="p">,</span>
            <span class="n">return_config</span><span class="o">=</span><span class="n">return_config</span><span class="p">,</span>
            <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">,</span>
            <span class="n">save_restore_connector</span><span class="o">=</span><span class="n">save_restore_connector</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">class</span> <span class="nc">typecheck</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Decorator to check the type of the input arguments.&quot;&quot;&quot;</span>

    <span class="k">class</span> <span class="nc">TypeState</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Placeholder to denote the default value of type information provided.</span>
<span class="sd">        If the constructor of this decorator is used to override the class level type definition,</span>
<span class="sd">        this enum value indicate that types will be overridden.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">UNINITIALIZED</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_types</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TypeState</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]]]</span> <span class="o">=</span> <span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span><span class="p">,</span>
        <span class="n">output_types</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TypeState</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]]]</span> <span class="o">=</span> <span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span><span class="p">,</span>
        <span class="n">ignore_collections</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A decorator which performs input-output neural type checks, and attaches</span>
<span class="sd">        neural types to the output of the function that it wraps.</span>
<span class="sd">        Requires that the class inherit from `mridc.core.Typing` in order to perform</span>
<span class="sd">        type checking, and will raise an error if that is not the case.</span>
<span class="sd">        # Usage (Class level type support)</span>
<span class="sd">        @typecheck()</span>
<span class="sd">        def fn(self, arg1, arg2, ...):</span>
<span class="sd">            ...</span>
<span class="sd">        # Usage (Function level type support)</span>
<span class="sd">        @typecheck(input_types=..., output_types=...)</span>
<span class="sd">        def fn(self, arg1, arg2, ...):</span>
<span class="sd">            ...</span>
<span class="sd">        Points to be noted:</span>
<span class="sd">        1) The brackets () in `@typecheck()` are necessary.</span>
<span class="sd">            You will encounter a TypeError: __init__() takes 1 positional argument but X</span>
<span class="sd">            were given without those brackets.</span>
<span class="sd">        2) The function can take any number of positional arguments during definition.</span>
<span class="sd">            When you call this function, all arguments must be passed using kwargs only.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_types</span> <span class="o">=</span> <span class="n">input_types</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_types</span> <span class="o">=</span> <span class="n">output_types</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_override</span> <span class="o">=</span> <span class="n">input_types</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_override</span> <span class="o">=</span> <span class="n">output_types</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_collections</span> <span class="o">=</span> <span class="n">ignore_collections</span>

    <span class="nd">@wrapt</span><span class="o">.</span><span class="n">decorator</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="n">is_typecheck_enabled</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wrapped</span><span class="p">,</span> <span class="n">instance</span><span class="p">:</span> <span class="n">Typing</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">instance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Only classes which inherit mridc.core.Typing can use this decorator !&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="n">Typing</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Only classes which inherit mridc.core.Typing can use this decorator !&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="s2">&quot;input_ports&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="s2">&quot;output_ports&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Typing requires override of `input_types()` and `output_types()`, &quot;</span>
                <span class="s2">&quot;not `input_ports() and `output_ports()`&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Preserve type information</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_types</span> <span class="ow">is</span> <span class="n">typecheck</span><span class="o">.</span><span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_types</span> <span class="o">=</span> <span class="n">instance</span><span class="o">.</span><span class="n">input_types</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_types</span> <span class="ow">is</span> <span class="n">typecheck</span><span class="o">.</span><span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_types</span> <span class="o">=</span> <span class="n">instance</span><span class="o">.</span><span class="n">output_types</span>

        <span class="c1"># Resolve global type or local overridden type</span>
        <span class="n">input_types</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_types</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_override</span> <span class="k">else</span> <span class="n">instance</span><span class="o">.</span><span class="n">input_types</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_override</span><span class="p">:</span>
            <span class="n">output_types</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_types</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_types</span> <span class="o">=</span> <span class="n">instance</span><span class="o">.</span><span class="n">output_types</span>

        <span class="c1"># If types are not defined, skip type checks and just call the wrapped method</span>
        <span class="k">if</span> <span class="n">input_types</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">output_types</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Check that all arguments are kwargs</span>
        <span class="k">if</span> <span class="n">input_types</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;All arguments must be passed by kwargs only for typed methods&quot;</span><span class="p">)</span>

        <span class="c1"># Perform rudimentary input checks here</span>
        <span class="n">instance</span><span class="o">.</span><span class="n">_validate_input_types</span><span class="p">(</span><span class="n">input_types</span><span class="o">=</span><span class="n">input_types</span><span class="p">,</span> <span class="n">ignore_collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ignore_collections</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Call the method - this can be forward, or any other callable method</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">instance</span><span class="o">.</span><span class="n">_attach_and_validate_output_types</span><span class="p">(</span>
            <span class="n">output_types</span><span class="o">=</span><span class="n">output_types</span><span class="p">,</span> <span class="n">ignore_collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ignore_collections</span><span class="p">,</span> <span class="n">out_objects</span><span class="o">=</span><span class="n">outputs</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">set_typecheck_enabled</span><span class="p">(</span><span class="n">enabled</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the global typecheck flag.&quot;&quot;&quot;</span>
        <span class="k">global</span> <span class="n">_TYPECHECK_ENABLED</span>
        <span class="n">_TYPECHECK_ENABLED</span> <span class="o">=</span> <span class="n">enabled</span>

    <span class="nd">@staticmethod</span>
    <span class="nd">@contextmanager</span>
    <span class="k">def</span> <span class="nf">disable_checks</span><span class="p">():</span>
        <span class="sd">&quot;&quot;&quot;Temporarily disable type checks.&quot;&quot;&quot;</span>
        <span class="n">typecheck</span><span class="o">.</span><span class="n">set_typecheck_enabled</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">typecheck</span><span class="o">.</span><span class="n">set_typecheck_enabled</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

        </details>

            </section>
                <section id="Typing">
                                <div class="attr class">
        <a class="headerlink" href="#Typing">#&nbsp;&nbsp</a>


        <span class="def">class</span>
        <span class="name">Typing</span><wbr>(<span class="base">abc.ABC</span>):
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Typing</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;An interface which endows module with neural types&quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_types</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Define these to enable input neural type checks&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output_types</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Define these to enable output neural type checks&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_validate_input_types</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_types</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_collections</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function does a few things.</span>
<span class="sd">        1) It ensures that len(self.input_types &lt;non-optional&gt;) &lt;= len(kwargs) &lt;= len(self.input_types).</span>
<span class="sd">        2) For each (keyword name, keyword value) passed as input to the wrapped function:</span>
<span class="sd">            - Check if the keyword name exists in the list of valid self.input_types names.</span>
<span class="sd">            - Check if keyword value has the `neural_type` property.</span>
<span class="sd">                - If it does, then perform a comparative check and assert that neural types</span>
<span class="sd">                    are compatible (SAME or GREATER).</span>
<span class="sd">            - Check if keyword value is a container type (list or tuple). If yes,</span>
<span class="sd">                then perform the elementwise test of neural type above on each element</span>
<span class="sd">                of the nested structure, recursively.</span>
<span class="sd">        Args:</span>
<span class="sd">            input_types: Either the `input_types` defined at class level, or the local function</span>
<span class="sd">                overridden type definition.</span>
<span class="sd">            ignore_collections: For backward compatibility, container support can be disabled explicitly</span>
<span class="sd">                using this flag. When set to True, all nesting is ignored and nest-depth checks are skipped.</span>
<span class="sd">            kwargs: Dictionary of argument_name:argument_value pairs passed to the wrapped</span>
<span class="sd">                function upon call.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: Properly implement this</span>
        <span class="k">if</span> <span class="n">input_types</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="c1"># Precompute metadata</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="n">TypecheckMetadata</span><span class="p">(</span><span class="n">original_types</span><span class="o">=</span><span class="n">input_types</span><span class="p">,</span> <span class="n">ignore_collections</span><span class="o">=</span><span class="n">ignore_collections</span><span class="p">)</span>

        <span class="n">total_input_types</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_types</span><span class="p">)</span>
        <span class="n">mandatory_input_types</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">mandatory_types</span><span class="p">)</span>

        <span class="c1"># Allow number of input arguments to be &lt;= total input neural types.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">mandatory_input_types</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">total_input_types</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Number of input arguments provided (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span><span class="si">}</span><span class="s2">) is not as expected. Function has &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">total_input_types</span><span class="si">}</span><span class="s2"> total inputs with </span><span class="si">{</span><span class="n">mandatory_input_types</span><span class="si">}</span><span class="s2"> mandatory inputs.&quot;</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># Check if keys exists in the defined input types</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">input_types</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Input argument </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> has no corresponding input_type match. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Existing input_types = </span><span class="si">{</span><span class="n">input_types</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

                <span class="c1"># Perform neural type check</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;neural_type&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">compare</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">neural_type</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span>
                <span class="n">NeuralTypeComparisonResult</span><span class="o">.</span><span class="n">SAME</span><span class="p">,</span>
                <span class="n">NeuralTypeComparisonResult</span><span class="o">.</span><span class="n">GREATER</span><span class="p">,</span>
            <span class="p">):</span>
                <span class="n">error_msg</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">input_types</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">compare</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">neural_type</span><span class="p">)</span><span class="si">}</span><span class="s2"> :&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;Input type expected : </span><span class="si">{</span><span class="n">input_types</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;Input type found : </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">neural_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;Argument: </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="p">]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dict_tuple</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">elements_type</span><span class="o">.</span><span class="n">type_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
                    <span class="n">error_msg</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;  input param_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> : </span><span class="si">{</span><span class="n">dict_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">dict_tuple</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">error_msg</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;  input param_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> : </span><span class="si">{</span><span class="n">dict_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">dict_tuple</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dict_tuple</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">neural_type</span><span class="o">.</span><span class="n">elements_type</span><span class="o">.</span><span class="n">type_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
                <span class="p">)</span>

                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">error_msg</span><span class="p">))</span>

                <span class="c1"># Perform input n dim check</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">):</span>
                <span class="n">value_shape</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">type_shape</span> <span class="o">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">axes</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">key</span>

                <span class="k">if</span> <span class="n">type_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">type_shape</span><span class="p">)):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Input shape mismatch occurred for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> in module </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> : </span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Input shape expected = </span><span class="si">{</span><span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">axes</span><span class="si">}</span><span class="s2"> | </span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Input shape found : </span><span class="si">{</span><span class="n">value_shape</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">:</span>
                    <span class="c1"># This initiates a DFS, tracking the depth count as it goes along the nested structure.</span>
                    <span class="c1"># Initial depth is 1 as we consider the current loop to be the 1st step inside the nest.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__check_neural_type</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_attach_and_validate_output_types</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out_objects</span><span class="p">,</span> <span class="n">ignore_collections</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">output_types</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function does a few things.</span>
<span class="sd">        1) It ensures that len(out_object) == len(self.output_types).</span>
<span class="sd">        2) If the output is a tensor (or list/tuple of list/tuple ... of tensors), it</span>
<span class="sd">            attaches a neural_type to it. For objects without the neural_type attribute,</span>
<span class="sd">            such as python objects (dictionaries and lists, primitive data types, structs),</span>
<span class="sd">            no neural_type is attached.</span>
<span class="sd">            Note: tensor.neural_type is only checked during _validate_input_types which is</span>
<span class="sd">            called prior to forward().</span>
<span class="sd">        Args:</span>
<span class="sd">            output_types: Either the `output_types` defined at class level, or the local function</span>
<span class="sd">                overridden type definition.</span>
<span class="sd">            ignore_collections: For backward compatibility, container support can be disabled explicitly</span>
<span class="sd">                using this flag. When set to True, all nesting is ignored and nest-depth checks are skipped.</span>
<span class="sd">            out_objects: The outputs of the wrapped function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: Properly implement this</span>
        <span class="k">if</span> <span class="n">output_types</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="c1"># Precompute metadata</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="n">TypecheckMetadata</span><span class="p">(</span><span class="n">original_types</span><span class="o">=</span><span class="n">output_types</span><span class="p">,</span> <span class="n">ignore_collections</span><span class="o">=</span><span class="n">ignore_collections</span><span class="p">)</span>
        <span class="n">out_types_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="n">mandatory_out_types_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">mandatory_types</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

        <span class="c1"># First convert all outputs to list/tuple format to check correct number of outputs</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">out_objects</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">out_container</span> <span class="o">=</span> <span class="n">out_objects</span>  <span class="c1"># can be any rank nested structure</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out_container</span> <span class="o">=</span> <span class="p">[</span><span class="n">out_objects</span><span class="p">]</span>

        <span class="c1"># If this neural type has a *single output*, with *support for nested outputs*,</span>
        <span class="c1"># then *do not* perform any check on the number of output items against the number</span>
        <span class="c1"># of neural types (in this case, 1).</span>
        <span class="c1"># This is done as python will *not* wrap a single returned list into a tuple of length 1,</span>
        <span class="c1"># instead opting to keep the list intact. Therefore len(out_container) in such a case</span>
        <span class="c1"># is the length of all the elements of that list - each of which has the same corresponding</span>
        <span class="c1"># neural type (defined as the singular container type).</span>
        <span class="k">if</span> <span class="n">metadata</span><span class="o">.</span><span class="n">is_singular_container_type</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="c1"># In all other cases, python will wrap multiple outputs into an outer tuple.</span>
        <span class="c1"># Allow number of output arguments to be &lt;= total output neural types and &gt;= mandatory outputs.</span>

        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_container</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_types_list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_container</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">mandatory_out_types_list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;Number of output arguments provided (</span><span class="si">{}</span><span class="s2">) is not as expected. It should be larger than </span><span class="si">{}</span><span class="s2"> and &quot;</span>
                <span class="s2">&quot;less than </span><span class="si">{}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;This can be either because insufficient/extra number of output NeuralTypes were provided,&quot;</span>
                <span class="s2">&quot;or the provided NeuralTypes </span><span class="si">{}</span><span class="s2"> should enable container support &quot;</span>
                <span class="s2">&quot;(add &#39;[]&#39; to the NeuralType definition)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">out_container</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_types_list</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">mandatory_out_types_list</span><span class="p">),</span> <span class="n">output_types</span>
                <span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># Attach types recursively, if possible</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out_objects</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out_objects</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="c1"># Here, out_objects is a single object which can potentially be attached with a NeuralType</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">out_objects</span><span class="o">.</span><span class="n">neural_type</span> <span class="o">=</span> <span class="n">out_types_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="k">pass</span>

                <span class="c1"># Perform output n dim check</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">out_objects</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">):</span>
                <span class="n">value_shape</span> <span class="o">=</span> <span class="n">out_objects</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">type_shape</span> <span class="o">=</span> <span class="n">out_types_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axes</span>
                <span class="k">if</span> <span class="n">type_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">type_shape</span><span class="p">):</span>
                    <span class="n">name</span> <span class="o">=</span> <span class="n">out_types_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Output shape mismatch occurred for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> in module </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> : </span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Output shape expected = </span><span class="si">{</span><span class="n">type_shape</span><span class="si">}</span><span class="s2"> | </span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Output shape found : </span><span class="si">{</span><span class="n">value_shape</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

        <span class="k">elif</span> <span class="n">metadata</span><span class="o">.</span><span class="n">is_singular_container_type</span><span class="p">:</span>
            <span class="c1"># If only a single neural type is provided, and it defines a container nest,</span>
            <span class="c1"># then all elements of the returned list/tuple are assumed to belong to that</span>
            <span class="c1"># singular neural type.</span>
            <span class="c1"># As such, the &quot;current&quot; depth inside the DFS loop is counted as 1,</span>
            <span class="c1"># and subsequent nesting will increase this count.</span>

            <span class="c1"># NOTE:</span>
            <span class="c1"># As the flag `is_singular_container_type` will activate only for</span>
            <span class="c1"># the case where there is 1 output type defined with container nesting,</span>
            <span class="c1"># this is a safe assumption to make.</span>
            <span class="n">depth</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="c1"># NOTE:</span>
            <span class="c1"># A user may chose to explicitly wrap the single output list within an explicit tuple</span>
            <span class="c1"># In such a case we reduce the &quot;current&quot; depth to 0 - to acknowledge the fact that</span>
            <span class="c1"># the actual nest exists within a wrapper tuple.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_objects</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">out_objects</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">tuple</span><span class="p">:</span>
                <span class="n">depth</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">out_objects</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__attach_neural_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">out_types_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If more then one item is returned in a return statement, python will wrap</span>
            <span class="c1"># the output with an outer tuple. Therefore there must be a 1:1 correspondence</span>
            <span class="c1"># of the output_neural type (with or without nested structure) to the actual output</span>
            <span class="c1"># (whether it is a single object or a nested structure of objects).</span>
            <span class="c1"># Therefore in such a case, we &quot;start&quot; the DFS at depth 0 - since the recursion is</span>
            <span class="c1"># being applied on 1 neural type : 1 output struct (single or nested output).</span>
            <span class="c1"># Since we are guaranteed that the outer tuple will be built by python,</span>
            <span class="c1"># assuming initial depth of 0 is appropriate.</span>
            <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">res</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">out_objects</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__attach_neural_type</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">out_types_list</span><span class="p">[</span><span class="n">ind</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">__check_neural_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Checks if the object is of the correct type, and attaches the correct NeuralType.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__check_neural_type</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
            <span class="k">return</span>  <span class="c1"># after processing nest, return to avoid testing nest itself</span>

        <span class="n">type_val</span> <span class="o">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

        <span class="c1"># If nest depth doesnt match neural type structure depth, raise an error</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">metadata</span><span class="o">.</span><span class="n">ignore_collections</span> <span class="ow">and</span> <span class="n">depth</span> <span class="o">!=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">container_depth</span><span class="p">[</span><span class="n">name</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;While checking input neural types,</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;Nested depth of value did not match container specification:</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Current nested depth of NeuralType &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; (</span><span class="si">{</span><span class="n">type_val</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">depth</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Expected nested depth : </span><span class="si">{</span><span class="n">metadata</span><span class="o">.</span><span class="n">container_depth</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;neural_type&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">type_val</span><span class="o">.</span><span class="n">compare</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">neural_type</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span>
            <span class="n">NeuralTypeComparisonResult</span><span class="o">.</span><span class="n">SAME</span><span class="p">,</span>
            <span class="n">NeuralTypeComparisonResult</span><span class="o">.</span><span class="n">GREATER</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">type_val</span><span class="o">.</span><span class="n">compare</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">neural_type</span><span class="p">)</span><span class="si">}</span><span class="s2"> : </span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Input type expected = </span><span class="si">{</span><span class="n">type_val</span><span class="si">}</span><span class="s2"> | </span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Input type found : </span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="n">neural_type</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Perform input n dim check</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">):</span>
            <span class="n">value_shape</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">type_shape</span> <span class="o">=</span> <span class="n">type_val</span><span class="o">.</span><span class="n">axes</span>

            <span class="k">if</span> <span class="n">type_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">type_shape</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Input shape mismatch occurred for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> in module </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> : </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Input shape expected = </span><span class="si">{</span><span class="n">type_shape</span><span class="si">}</span><span class="s2"> | </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Input shape found : </span><span class="si">{</span><span class="n">value_shape</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__attach_neural_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Attach NeuralType to the object.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">obj</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__attach_neural_type</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
            <span class="k">return</span>  <span class="c1"># after processing nest, return to avoid argument insertion into nest itself</span>

        <span class="n">type_val</span> <span class="o">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">base_types</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

        <span class="c1"># If nest depth doesnt match neural type structure depth, raise an error</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">metadata</span><span class="o">.</span><span class="n">ignore_collections</span> <span class="ow">and</span> <span class="n">depth</span> <span class="o">!=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">container_depth</span><span class="p">[</span><span class="n">name</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;While attaching output neural types,</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;Nested depth of value did not match container specification:</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Current nested depth of NeuralType &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; (</span><span class="si">{</span><span class="n">type_val</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">depth</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Expected nested depth : </span><span class="si">{</span><span class="n">metadata</span><span class="o">.</span><span class="n">container_depth</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">obj</span><span class="o">.</span><span class="n">neural_type</span> <span class="o">=</span> <span class="n">type_val</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="c1"># Perform output n dim check</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">):</span>
            <span class="n">value_shape</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">type_shape</span> <span class="o">=</span> <span class="n">type_val</span><span class="o">.</span><span class="n">axes</span>

            <span class="k">if</span> <span class="n">type_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_shape</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">type_shape</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Output shape mismatch occurred for </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> in module </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> : </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Output shape expected = </span><span class="si">{</span><span class="n">type_shape</span><span class="si">}</span><span class="s2"> | </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Output shape found : </span><span class="si">{</span><span class="n">value_shape</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>An interface which endows module with neural types</p>
</div>


                            <div id="Typing.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Typing.__init__">#&nbsp;&nbsp</a>


            <span class="name">Typing</span><span class="signature">()</span>
    </div>




                            </div>
                            <div id="Typing.input_types" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#Typing.input_types">#&nbsp;&nbsp</a>

        <span class="name">input_types</span><span class="annotation">: Optional[Dict[str, <a href="../neural_types/neural_type.html#NeuralType">mridc.core.neural_types.neural_type.NeuralType</a>]]</span>
    </div>


            <div class="docstring"><p>Define these to enable input neural type checks</p>
</div>


                            </div>
                            <div id="Typing.output_types" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#Typing.output_types">#&nbsp;&nbsp</a>

        <span class="name">output_types</span><span class="annotation">: Optional[Dict[str, <a href="../neural_types/neural_type.html#NeuralType">mridc.core.neural_types.neural_type.NeuralType</a>]]</span>
    </div>


            <div class="docstring"><p>Define these to enable output neural type checks</p>
</div>


                            </div>
                </section>
                <section id="FileIO">
                                <div class="attr class">
        <a class="headerlink" href="#FileIO">#&nbsp;&nbsp</a>


        <span class="def">class</span>
        <span class="name">FileIO</span><wbr>(<span class="base">abc.ABC</span>):
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span><span class="k">class</span> <span class="nc">FileIO</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for file IO.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">save_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Saves module/model with weights&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">restore_from</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">restore_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">override_config_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">map_location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">return_config</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">trainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Trainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">save_restore_connector</span><span class="p">:</span> <span class="n">SaveRestoreConnector</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Restores module/model with weights&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_config_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">path2yaml_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiates an instance of mridc Model from YAML config file.</span>
<span class="sd">        Weights will be initialized randomly.</span>
<span class="sd">        Args:</span>
<span class="sd">            path2yaml_file: path to yaml file with model configuration</span>
<span class="sd">        Returns:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">Serialization</span><span class="p">):</span>
            <span class="n">conf</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path2yaml_file</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_config_dict</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">to_config_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path2yaml_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves current instance&#39;s configuration to YAML config file. Weights will not be saved.</span>
<span class="sd">        Args:</span>
<span class="sd">            path2yaml_file: path2yaml_file: path to yaml file where model model configuration will be saved</span>
<span class="sd">        Returns:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cfg&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">maybe_update_config_version</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path2yaml_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fout</span><span class="p">:</span>
                <span class="n">OmegaConf</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">fout</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>

        </details>

            <div class="docstring"><p>Base class for file IO.</p>
</div>


                            <div id="FileIO.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FileIO.__init__">#&nbsp;&nbsp</a>


            <span class="name">FileIO</span><span class="signature">()</span>
    </div>




                            </div>
                            <div id="FileIO.save_to" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FileIO.save_to">#&nbsp;&nbsp</a>


            <span class="def">def</span>
            <span class="name">save_to</span><span class="signature">(self, save_path: str)</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">save_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Saves module/model with weights&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>

        </details>

            <div class="docstring"><p>Saves module/model with weights</p>
</div>


                            </div>
                            <div id="FileIO.restore_from" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FileIO.restore_from">#&nbsp;&nbsp</a>

                <div class="decorator">@classmethod</div>

            <span class="def">def</span>
            <span class="name">restore_from</span><span class="signature">(
    cls,
    restore_path: str,
    override_config_path: Optional[str] = None,
    map_location: Optional[torch.device] = None,
    strict: bool = True,
    return_config: bool = False,
    trainer: Optional[pytorch_lightning.trainer.trainer.Trainer] = None,
    save_restore_connector: <a href="../connectors/save_restore_connector.html#SaveRestoreConnector">mridc.core.connectors.save_restore_connector.SaveRestoreConnector</a> = None
)</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">restore_from</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">restore_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">override_config_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">map_location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">return_config</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">trainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Trainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">save_restore_connector</span><span class="p">:</span> <span class="n">SaveRestoreConnector</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Restores module/model with weights&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>

        </details>

            <div class="docstring"><p>Restores module/model with weights</p>
</div>


                            </div>
                            <div id="FileIO.from_config_file" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FileIO.from_config_file">#&nbsp;&nbsp</a>

                <div class="decorator">@classmethod</div>

            <span class="def">def</span>
            <span class="name">from_config_file</span><span class="signature">(cls, path2yaml_file: str)</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_config_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">path2yaml_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiates an instance of mridc Model from YAML config file.</span>
<span class="sd">        Weights will be initialized randomly.</span>
<span class="sd">        Args:</span>
<span class="sd">            path2yaml_file: path to yaml file with model configuration</span>
<span class="sd">        Returns:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">Serialization</span><span class="p">):</span>
            <span class="n">conf</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path2yaml_file</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_config_dict</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">conf</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>

        </details>

            <div class="docstring"><p>Instantiates an instance of mridc Model from YAML config file.
Weights will be initialized randomly.
Args:
    path2yaml_file: path to yaml file with model configuration
Returns:</p>
</div>


                            </div>
                            <div id="FileIO.to_config_file" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#FileIO.to_config_file">#&nbsp;&nbsp</a>


            <span class="def">def</span>
            <span class="name">to_config_file</span><span class="signature">(self, path2yaml_file: str)</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">to_config_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path2yaml_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves current instance&#39;s configuration to YAML config file. Weights will not be saved.</span>
<span class="sd">        Args:</span>
<span class="sd">            path2yaml_file: path2yaml_file: path to yaml file where model model configuration will be saved</span>
<span class="sd">        Returns:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cfg&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">maybe_update_config_version</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path2yaml_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fout</span><span class="p">:</span>
                <span class="n">OmegaConf</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">fout</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>

        </details>

            <div class="docstring"><p>Saves current instance's configuration to YAML config file. Weights will not be saved.
Args:
    path2yaml_file: path2yaml_file: path to yaml file where model model configuration will be saved
Returns:</p>
</div>


                            </div>
                </section>
                <section id="Model">
                                <div class="attr class">
        <a class="headerlink" href="#Model">#&nbsp;&nbsp</a>


        <span class="def">class</span>
        <span class="name">Model</span><wbr>(<span class="base"><a href="#Typing">Typing</a></span>, <span class="base"><a href="#Serialization">Serialization</a></span>, <span class="base"><a href="#FileIO">FileIO</a></span>, <span class="base">abc.ABC</span>):
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">Typing</span><span class="p">,</span> <span class="n">Serialization</span><span class="p">,</span> <span class="n">FileIO</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
    <span class="sd">&quot;&quot;&quot;Abstract class offering interface which should be implemented by all mridc models.&quot;&quot;&quot;</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">list_available_models</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PretrainedModelInfo</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Should list all pre-trained models available.</span>
<span class="sd">        Note: There is no check that requires model names and aliases to be unique. In the case of a collision,</span>
<span class="sd">        whatever model (or alias) is listed first in the this returned list will be instantiated.</span>
<span class="sd">        Returns:</span>
<span class="sd">            A list of PretrainedModelInfo entries</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">get_available_model_names</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the list of model names available.</span>
<span class="sd">        to get the complete model description use list_available_models()</span>
<span class="sd">        Returns:</span>
<span class="sd">            A list of model names</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">()]</span>  <span class="c1"># type: ignore</span>
            <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="p">[]</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">refresh_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">override_config_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">map_location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">return_config</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">trainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Trainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">save_restore_connector</span><span class="p">:</span> <span class="n">SaveRestoreConnector</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiates an instance of mridc</span>
<span class="sd">        Use restore_from() to instantiate from a local .mridc file.</span>
<span class="sd">        Args:</span>
<span class="sd">            model_name: string key which will be used to find the module.</span>
<span class="sd">            refresh_cache: If set to True, then when fetching from cloud, this will re-fetch the file</span>
<span class="sd">                from cloud even if it is already found in a cache locally.</span>
<span class="sd">            override_config_path: path to a yaml config that will override the internal</span>
<span class="sd">                config file</span>
<span class="sd">            map_location: Optional torch.device() to map the instantiated model to a device.</span>
<span class="sd">                By default (None), it will select a GPU if available, falling back to CPU otherwise.</span>
<span class="sd">            strict: Passed to torch.load_state_dict. By default true.</span>
<span class="sd">            return_config: If set to true, will return just the underlying config of the restored</span>
<span class="sd">                model as an OmegaConf DictConfig object without instantiating the model.</span>
<span class="sd">            trainer: Optional Trainer object to use for restoring the model.</span>
<span class="sd">            save_restore_connector: Optional SaveRestoreConnector object to use for restoring the model.</span>
<span class="sd">        Returns:</span>
<span class="sd">            A model instance of a particular model class or its underlying config (if return_config is set).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">save_restore_connector</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">save_restore_connector</span> <span class="o">=</span> <span class="n">SaveRestoreConnector</span><span class="p">()</span>

        <span class="n">location_in_the_cloud</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">description</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">models</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">pretrained_model_info</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">():</span>  <span class="c1"># type: ignore</span>
                <span class="n">found</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">if</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="o">==</span> <span class="n">model_name</span><span class="p">:</span>
                    <span class="n">found</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">elif</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">aliases</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">alias</span> <span class="ow">in</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">aliases</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">alias</span> <span class="o">==</span> <span class="n">model_name</span><span class="p">:</span>
                            <span class="n">found</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="k">break</span>
                <span class="k">if</span> <span class="n">found</span><span class="p">:</span>
                    <span class="n">location_in_the_cloud</span> <span class="o">=</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">location</span>
                    <span class="n">description</span> <span class="o">=</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">description</span>
                    <span class="n">class_</span> <span class="o">=</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">class_</span>
                    <span class="k">break</span>

        <span class="k">if</span> <span class="n">location_in_the_cloud</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> was not found. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Check cls.list_available_models() for the list of all available models.&quot;</span>
            <span class="p">)</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">location_in_the_cloud</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">url</span> <span class="o">=</span> <span class="n">location_in_the_cloud</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">resolve_cache_dir</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename</span><span class="p">[:</span><span class="o">-</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="c1"># If either description and location in the cloud changes, this will force re-download</span>
        <span class="c1"># of the model.</span>
        <span class="n">cache_subfolder</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">sha512</span><span class="p">((</span><span class="n">location_in_the_cloud</span> <span class="o">+</span> <span class="n">description</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>
        <span class="c1"># if file exists on cache_folder/subfolder, it will be re-used, unless refresh_cache is True</span>
        <span class="n">mridc_model_file_in_cache</span> <span class="o">=</span> <span class="n">maybe_download_from_cloud</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span> <span class="n">subfolder</span><span class="o">=</span><span class="n">cache_subfolder</span><span class="p">,</span> <span class="n">refresh_cache</span><span class="o">=</span><span class="n">refresh_cache</span>
        <span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Instantiating model from pre-trained checkpoint&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">class_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">class_</span> <span class="o">=</span> <span class="bp">cls</span>

        <span class="k">return</span> <span class="n">class_</span><span class="o">.</span><span class="n">restore_from</span><span class="p">(</span>
            <span class="n">restore_path</span><span class="o">=</span><span class="n">mridc_model_file_in_cache</span><span class="p">,</span>
            <span class="n">override_config_path</span><span class="o">=</span><span class="n">override_config_path</span><span class="p">,</span>
            <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">,</span>
            <span class="n">strict</span><span class="o">=</span><span class="n">strict</span><span class="p">,</span>
            <span class="n">return_config</span><span class="o">=</span><span class="n">return_config</span><span class="p">,</span>
            <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">,</span>
            <span class="n">save_restore_connector</span><span class="o">=</span><span class="n">save_restore_connector</span><span class="p">,</span>
        <span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>Abstract class offering interface which should be implemented by all mridc models.</p>
</div>


                            <div id="Model.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Model.__init__">#&nbsp;&nbsp</a>


            <span class="name">Model</span><span class="signature">()</span>
    </div>




                            </div>
                            <div id="Model.list_available_models" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Model.list_available_models">#&nbsp;&nbsp</a>

                <div class="decorator">@classmethod</div>

            <span class="def">def</span>
            <span class="name">list_available_models</span><span class="signature">(cls) -&gt; Optional[<a href="#PretrainedModelInfo">mridc.core.classes.common.PretrainedModelInfo</a>]</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">list_available_models</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PretrainedModelInfo</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Should list all pre-trained models available.</span>
<span class="sd">        Note: There is no check that requires model names and aliases to be unique. In the case of a collision,</span>
<span class="sd">        whatever model (or alias) is listed first in the this returned list will be instantiated.</span>
<span class="sd">        Returns:</span>
<span class="sd">            A list of PretrainedModelInfo entries</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>

        </details>

            <div class="docstring"><p>Should list all pre-trained models available.
Note: There is no check that requires model names and aliases to be unique. In the case of a collision,
whatever model (or alias) is listed first in the this returned list will be instantiated.
Returns:
    A list of PretrainedModelInfo entries</p>
</div>


                            </div>
                            <div id="Model.get_available_model_names" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Model.get_available_model_names">#&nbsp;&nbsp</a>

                <div class="decorator">@classmethod</div>

            <span class="def">def</span>
            <span class="name">get_available_model_names</span><span class="signature">(cls) -&gt; List[str]</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">get_available_model_names</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the list of model names available.</span>
<span class="sd">        to get the complete model description use list_available_models()</span>
<span class="sd">        Returns:</span>
<span class="sd">            A list of model names</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">()]</span>  <span class="c1"># type: ignore</span>
            <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">()</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="p">[]</span>
        <span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>Returns the list of model names available.
to get the complete model description use list_available_models()
Returns:
    A list of model names</p>
</div>


                            </div>
                            <div id="Model.from_pretrained" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Model.from_pretrained">#&nbsp;&nbsp</a>

                <div class="decorator">@classmethod</div>

            <span class="def">def</span>
            <span class="name">from_pretrained</span><span class="signature">(
    cls,
    model_name: str,
    refresh_cache: bool = False,
    override_config_path: Optional[str] = None,
    map_location: Optional[torch.device] = None,
    strict: bool = True,
    return_config: bool = False,
    trainer: Optional[pytorch_lightning.trainer.trainer.Trainer] = None,
    save_restore_connector: <a href="../connectors/save_restore_connector.html#SaveRestoreConnector">mridc.core.connectors.save_restore_connector.SaveRestoreConnector</a> = None
)</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">refresh_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">override_config_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">map_location</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">return_config</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">trainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Trainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">save_restore_connector</span><span class="p">:</span> <span class="n">SaveRestoreConnector</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiates an instance of mridc</span>
<span class="sd">        Use restore_from() to instantiate from a local .mridc file.</span>
<span class="sd">        Args:</span>
<span class="sd">            model_name: string key which will be used to find the module.</span>
<span class="sd">            refresh_cache: If set to True, then when fetching from cloud, this will re-fetch the file</span>
<span class="sd">                from cloud even if it is already found in a cache locally.</span>
<span class="sd">            override_config_path: path to a yaml config that will override the internal</span>
<span class="sd">                config file</span>
<span class="sd">            map_location: Optional torch.device() to map the instantiated model to a device.</span>
<span class="sd">                By default (None), it will select a GPU if available, falling back to CPU otherwise.</span>
<span class="sd">            strict: Passed to torch.load_state_dict. By default true.</span>
<span class="sd">            return_config: If set to true, will return just the underlying config of the restored</span>
<span class="sd">                model as an OmegaConf DictConfig object without instantiating the model.</span>
<span class="sd">            trainer: Optional Trainer object to use for restoring the model.</span>
<span class="sd">            save_restore_connector: Optional SaveRestoreConnector object to use for restoring the model.</span>
<span class="sd">        Returns:</span>
<span class="sd">            A model instance of a particular model class or its underlying config (if return_config is set).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">save_restore_connector</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">save_restore_connector</span> <span class="o">=</span> <span class="n">SaveRestoreConnector</span><span class="p">()</span>

        <span class="n">location_in_the_cloud</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">description</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">models</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">models</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">pretrained_model_info</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">list_available_models</span><span class="p">():</span>  <span class="c1"># type: ignore</span>
                <span class="n">found</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">if</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="o">==</span> <span class="n">model_name</span><span class="p">:</span>
                    <span class="n">found</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">elif</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">aliases</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">alias</span> <span class="ow">in</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">aliases</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">alias</span> <span class="o">==</span> <span class="n">model_name</span><span class="p">:</span>
                            <span class="n">found</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="k">break</span>
                <span class="k">if</span> <span class="n">found</span><span class="p">:</span>
                    <span class="n">location_in_the_cloud</span> <span class="o">=</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">location</span>
                    <span class="n">description</span> <span class="o">=</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">description</span>
                    <span class="n">class_</span> <span class="o">=</span> <span class="n">pretrained_model_info</span><span class="o">.</span><span class="n">class_</span>
                    <span class="k">break</span>

        <span class="k">if</span> <span class="n">location_in_the_cloud</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> was not found. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Check cls.list_available_models() for the list of all available models.&quot;</span>
            <span class="p">)</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">location_in_the_cloud</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">url</span> <span class="o">=</span> <span class="n">location_in_the_cloud</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">resolve_cache_dir</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename</span><span class="p">[:</span><span class="o">-</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="c1"># If either description and location in the cloud changes, this will force re-download</span>
        <span class="c1"># of the model.</span>
        <span class="n">cache_subfolder</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">sha512</span><span class="p">((</span><span class="n">location_in_the_cloud</span> <span class="o">+</span> <span class="n">description</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>
        <span class="c1"># if file exists on cache_folder/subfolder, it will be re-used, unless refresh_cache is True</span>
        <span class="n">mridc_model_file_in_cache</span> <span class="o">=</span> <span class="n">maybe_download_from_cloud</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span> <span class="n">subfolder</span><span class="o">=</span><span class="n">cache_subfolder</span><span class="p">,</span> <span class="n">refresh_cache</span><span class="o">=</span><span class="n">refresh_cache</span>
        <span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Instantiating model from pre-trained checkpoint&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">class_</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">class_</span> <span class="o">=</span> <span class="bp">cls</span>

        <span class="k">return</span> <span class="n">class_</span><span class="o">.</span><span class="n">restore_from</span><span class="p">(</span>
            <span class="n">restore_path</span><span class="o">=</span><span class="n">mridc_model_file_in_cache</span><span class="p">,</span>
            <span class="n">override_config_path</span><span class="o">=</span><span class="n">override_config_path</span><span class="p">,</span>
            <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">,</span>
            <span class="n">strict</span><span class="o">=</span><span class="n">strict</span><span class="p">,</span>
            <span class="n">return_config</span><span class="o">=</span><span class="n">return_config</span><span class="p">,</span>
            <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">,</span>
            <span class="n">save_restore_connector</span><span class="o">=</span><span class="n">save_restore_connector</span><span class="p">,</span>
        <span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>Instantiates an instance of mridc
Use restore_from() to instantiate from a local .mridc file.
Args:
    model_name: string key which will be used to find the module.
    refresh_cache: If set to True, then when fetching from cloud, this will re-fetch the file
        from cloud even if it is already found in a cache locally.
    override_config_path: path to a yaml config that will override the internal
        config file
    map_location: Optional torch.device() to map the instantiated model to a device.
        By default (None), it will select a GPU if available, falling back to CPU otherwise.
    strict: Passed to torch.load_state_dict. By default true.
    return_config: If set to true, will return just the underlying config of the restored
        model as an OmegaConf DictConfig object without instantiating the model.
    trainer: Optional Trainer object to use for restoring the model.
    save_restore_connector: Optional SaveRestoreConnector object to use for restoring the model.
Returns:
    A model instance of a particular model class or its underlying config (if return_config is set).</p>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#Typing">Typing</a></dt>
                                <dd id="Model.input_types" class="variable"><a href="#Typing.input_types">input_types</a></dd>
                <dd id="Model.output_types" class="variable"><a href="#Typing.output_types">output_types</a></dd>

            </div>
            <div><dt><a href="#Serialization">Serialization</a></dt>
                                <dd id="Model.from_config_dict" class="function"><a href="#Serialization.from_config_dict">from_config_dict</a></dd>
                <dd id="Model.to_config_dict" class="function"><a href="#Serialization.to_config_dict">to_config_dict</a></dd>

            </div>
            <div><dt><a href="#FileIO">FileIO</a></dt>
                                <dd id="Model.save_to" class="function"><a href="#FileIO.save_to">save_to</a></dd>
                <dd id="Model.restore_from" class="function"><a href="#FileIO.restore_from">restore_from</a></dd>
                <dd id="Model.from_config_file" class="function"><a href="#FileIO.from_config_file">from_config_file</a></dd>
                <dd id="Model.to_config_file" class="function"><a href="#FileIO.to_config_file">to_config_file</a></dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="PretrainedModelInfo">
                                <div class="attr class">
        <a class="headerlink" href="#PretrainedModelInfo">#&nbsp;&nbsp</a>

                <div class="decorator">@total_ordering</div>
        <div class="decorator">@dataclass</div>

        <span class="def">class</span>
        <span class="name">PretrainedModelInfo</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span><span class="nd">@total_ordering</span>
<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">PretrainedModelInfo</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Class to store information about a pretrained model.&quot;&quot;&quot;</span>

    <span class="n">pretrained_model_name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">description</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">location</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">class_</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">aliases</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">base</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="n">extras</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;pretrained_model_name=</span><span class="si">{pretrained_model_name}</span><span class="s2">,</span><span class="se">\n\t</span><span class="s2">&quot;</span>
            <span class="s2">&quot;description=</span><span class="si">{description}</span><span class="s2">,</span><span class="se">\n\t</span><span class="s2">&quot;</span>
            <span class="s2">&quot;location=</span><span class="si">{location}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">extras</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{extras}</span><span class="s2">,</span><span class="se">\n\t</span><span class="s2">&quot;</span> <span class="s2">&quot;class_=</span><span class="si">{class_}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">extras</span><span class="o">=</span><span class="n">extras</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>

        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">base</span><span class="si">}</span><span class="s2">(</span><span class="se">\n\t</span><span class="si">{</span><span class="n">extras</span><span class="si">}</span><span class="se">\n</span><span class="s2">)&quot;</span>

    <span class="k">def</span> <span class="fm">__hash__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">hash</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">location</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="c1"># another object is equal to self, iff</span>
        <span class="c1"># if it&#39;s hash is equal to hash(self)</span>
        <span class="k">return</span> <span class="nb">hash</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="nb">hash</span><span class="p">(</span><span class="n">other</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">pretrained_model_name</span>

    <span class="k">def</span> <span class="fm">__lt__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="o">&lt;</span> <span class="n">other</span><span class="o">.</span><span class="n">pretrained_model_name</span>
</pre></div>

        </details>

            <div class="docstring"><p>Class to store information about a pretrained model.</p>
</div>


                            <div id="PretrainedModelInfo.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#PretrainedModelInfo.__init__">#&nbsp;&nbsp</a>


            <span class="name">PretrainedModelInfo</span><span class="signature">(
    pretrained_model_name: str,
    description: str,
    location: str,
    class_: Optional[<a href="#Model">mridc.core.classes.common.Model</a>] = None,
    aliases: Optional[List[str]] = None
)</span>
    </div>




                            </div>
                            <div id="PretrainedModelInfo.class_" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#PretrainedModelInfo.class_">#&nbsp;&nbsp</a>

        <span class="name">class_</span><span class="annotation">: Optional[<a href="#Model">mridc.core.classes.common.Model</a>]</span><span class="default_value"> = None</span>
    </div>




                            </div>
                            <div id="PretrainedModelInfo.aliases" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#PretrainedModelInfo.aliases">#&nbsp;&nbsp</a>

        <span class="name">aliases</span><span class="annotation">: Optional[List[str]]</span><span class="default_value"> = None</span>
    </div>




                            </div>
                </section>
                <section id="Serialization">
                                <div class="attr class">
        <a class="headerlink" href="#Serialization">#&nbsp;&nbsp</a>


        <span class="def">class</span>
        <span class="name">Serialization</span><wbr>(<span class="base">abc.ABC</span>):
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Serialization</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for serialization.&quot;&quot;&quot;</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_config_dict</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="s2">&quot;DictConfig&quot;</span><span class="p">,</span> <span class="n">trainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Trainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiates object using DictConfig-based configuration&quot;&quot;&quot;</span>
        <span class="c1"># Resolve the config dict</span>
        <span class="k">if</span> <span class="n">_HAS_HYDRA</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">DictConfig</span><span class="p">):</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
                <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

            <span class="n">config</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">maybe_update_config_version</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

        <span class="c1"># Hydra 0.x API</span>
        <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;cls&quot;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">or</span> <span class="s2">&quot;target&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;params&quot;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">and</span> <span class="n">_HAS_HYDRA</span><span class="p">:</span>
            <span class="c1"># regular hydra-based instantiation</span>
            <span class="n">instance</span> <span class="o">=</span> <span class="n">hydra</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">instantiate</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
        <span class="c1"># Hydra 1.x API</span>
        <span class="k">elif</span> <span class="s2">&quot;_target_&quot;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">and</span> <span class="n">_HAS_HYDRA</span><span class="p">:</span>
            <span class="c1"># regular hydra-based instantiation</span>
            <span class="n">instance</span> <span class="o">=</span> <span class="n">hydra</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">instantiate</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">instance</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">imported_cls_tb</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">instance_init_error</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="c1"># Attempt class path resolution from config `target` class (if it exists)</span>
            <span class="k">if</span> <span class="s2">&quot;target&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="n">target_cls</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>  <span class="c1"># No guarantee that this is a omegaconf class</span>
                <span class="n">imported_cls</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># try to import the target class</span>
                    <span class="n">imported_cls</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">import_class_by_path</span><span class="p">(</span><span class="n">target_cls</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                    <span class="n">imported_cls_tb</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>

                <span class="c1"># try instantiating model with target class</span>
                <span class="k">if</span> <span class="n">imported_cls</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># if calling class (cls) is subclass of imported class,</span>
                    <span class="c1"># use subclass instead</span>
                    <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">imported_cls</span><span class="p">):</span>
                        <span class="n">imported_cls</span> <span class="o">=</span> <span class="bp">cls</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">accepts_trainer</span> <span class="o">=</span> <span class="n">Serialization</span><span class="o">.</span><span class="n">_inspect_signature_for_trainer</span><span class="p">(</span><span class="n">imported_cls</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">accepts_trainer</span><span class="p">:</span>
                            <span class="n">instance</span> <span class="o">=</span> <span class="n">imported_cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">instance</span> <span class="o">=</span> <span class="n">imported_cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="n">imported_cls_tb</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
                        <span class="n">instance_init_error</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                        <span class="n">instance</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># target class resolution was unsuccessful, fall back to current `cls`</span>
            <span class="k">if</span> <span class="n">instance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">imported_cls_tb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Model instantiation from target class </span><span class="si">{</span><span class="n">target_cls</span><span class="si">}</span><span class="s2"> failed with following error.</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Falling back to `cls`.</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">imported_cls_tb</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="n">accepts_trainer</span> <span class="o">=</span> <span class="n">Serialization</span><span class="o">.</span><span class="n">_inspect_signature_for_trainer</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">accepts_trainer</span><span class="p">:</span>
                        <span class="n">instance</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">instance</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">imported_cls_tb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Instance failed restore_from due to: </span><span class="si">{</span><span class="n">instance_init_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">imported_cls_tb</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="n">e</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="s2">&quot;_cfg&quot;</span><span class="p">):</span>
            <span class="n">instance</span><span class="o">.</span><span class="n">_cfg</span> <span class="o">=</span> <span class="n">config</span>
        <span class="k">return</span> <span class="n">instance</span>

    <span class="k">def</span> <span class="nf">to_config_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;DictConfig&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns object&#39;s configuration to config dictionary&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cfg&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
            <span class="c1"># Resolve the config dict</span>
            <span class="k">if</span> <span class="n">_HAS_HYDRA</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">,</span> <span class="n">DictConfig</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
                <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

                <span class="n">config</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">maybe_update_config_version</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="o">=</span> <span class="n">config</span>

            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;to_config_dict() can currently only return object._cfg but current object does not have it.&quot;</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_inspect_signature_for_trainer</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">check_cls</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Inspects the signature of the class to see if it accepts a trainer argument.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">check_cls</span><span class="p">,</span> <span class="s2">&quot;__init__&quot;</span><span class="p">):</span>
            <span class="n">signature</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">check_cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">Trainer</span> <span class="ow">in</span> <span class="n">signature</span><span class="o">.</span><span class="n">parameters</span>
        <span class="k">return</span> <span class="kc">False</span>
</pre></div>

        </details>

            <div class="docstring"><p>Base class for serialization.</p>
</div>


                            <div id="Serialization.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Serialization.__init__">#&nbsp;&nbsp</a>


            <span class="name">Serialization</span><span class="signature">()</span>
    </div>




                            </div>
                            <div id="Serialization.from_config_dict" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Serialization.from_config_dict">#&nbsp;&nbsp</a>

                <div class="decorator">@classmethod</div>

            <span class="def">def</span>
            <span class="name">from_config_dict</span><span class="signature">(
    cls,
    config: omegaconf.dictconfig.DictConfig,
    trainer: Optional[pytorch_lightning.trainer.trainer.Trainer] = None
)</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_config_dict</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="s2">&quot;DictConfig&quot;</span><span class="p">,</span> <span class="n">trainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Trainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiates object using DictConfig-based configuration&quot;&quot;&quot;</span>
        <span class="c1"># Resolve the config dict</span>
        <span class="k">if</span> <span class="n">_HAS_HYDRA</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">DictConfig</span><span class="p">):</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
                <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

            <span class="n">config</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">maybe_update_config_version</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

        <span class="c1"># Hydra 0.x API</span>
        <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;cls&quot;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">or</span> <span class="s2">&quot;target&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;params&quot;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">and</span> <span class="n">_HAS_HYDRA</span><span class="p">:</span>
            <span class="c1"># regular hydra-based instantiation</span>
            <span class="n">instance</span> <span class="o">=</span> <span class="n">hydra</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">instantiate</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
        <span class="c1"># Hydra 1.x API</span>
        <span class="k">elif</span> <span class="s2">&quot;_target_&quot;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">and</span> <span class="n">_HAS_HYDRA</span><span class="p">:</span>
            <span class="c1"># regular hydra-based instantiation</span>
            <span class="n">instance</span> <span class="o">=</span> <span class="n">hydra</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">instantiate</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">instance</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">imported_cls_tb</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">instance_init_error</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="c1"># Attempt class path resolution from config `target` class (if it exists)</span>
            <span class="k">if</span> <span class="s2">&quot;target&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="n">target_cls</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>  <span class="c1"># No guarantee that this is a omegaconf class</span>
                <span class="n">imported_cls</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># try to import the target class</span>
                    <span class="n">imported_cls</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">import_class_by_path</span><span class="p">(</span><span class="n">target_cls</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                    <span class="n">imported_cls_tb</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>

                <span class="c1"># try instantiating model with target class</span>
                <span class="k">if</span> <span class="n">imported_cls</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># if calling class (cls) is subclass of imported class,</span>
                    <span class="c1"># use subclass instead</span>
                    <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">imported_cls</span><span class="p">):</span>
                        <span class="n">imported_cls</span> <span class="o">=</span> <span class="bp">cls</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">accepts_trainer</span> <span class="o">=</span> <span class="n">Serialization</span><span class="o">.</span><span class="n">_inspect_signature_for_trainer</span><span class="p">(</span><span class="n">imported_cls</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">accepts_trainer</span><span class="p">:</span>
                            <span class="n">instance</span> <span class="o">=</span> <span class="n">imported_cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">instance</span> <span class="o">=</span> <span class="n">imported_cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

                    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="n">imported_cls_tb</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
                        <span class="n">instance_init_error</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                        <span class="n">instance</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># target class resolution was unsuccessful, fall back to current `cls`</span>
            <span class="k">if</span> <span class="n">instance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">imported_cls_tb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Model instantiation from target class </span><span class="si">{</span><span class="n">target_cls</span><span class="si">}</span><span class="s2"> failed with following error.</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Falling back to `cls`.</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">imported_cls_tb</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="n">accepts_trainer</span> <span class="o">=</span> <span class="n">Serialization</span><span class="o">.</span><span class="n">_inspect_signature_for_trainer</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">accepts_trainer</span><span class="p">:</span>
                        <span class="n">instance</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">instance</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">imported_cls_tb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Instance failed restore_from due to: </span><span class="si">{</span><span class="n">instance_init_error</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">imported_cls_tb</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="n">e</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="s2">&quot;_cfg&quot;</span><span class="p">):</span>
            <span class="n">instance</span><span class="o">.</span><span class="n">_cfg</span> <span class="o">=</span> <span class="n">config</span>
        <span class="k">return</span> <span class="n">instance</span>
</pre></div>

        </details>

            <div class="docstring"><p>Instantiates object using DictConfig-based configuration</p>
</div>


                            </div>
                            <div id="Serialization.to_config_dict" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#Serialization.to_config_dict">#&nbsp;&nbsp</a>


            <span class="def">def</span>
            <span class="name">to_config_dict</span><span class="signature">(self) -&gt; omegaconf.dictconfig.DictConfig</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">to_config_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;DictConfig&quot;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns object&#39;s configuration to config dictionary&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cfg&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
            <span class="c1"># Resolve the config dict</span>
            <span class="k">if</span> <span class="n">_HAS_HYDRA</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">,</span> <span class="n">DictConfig</span><span class="p">):</span>  <span class="c1"># type: ignore</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
                <span class="n">OmegaConf</span><span class="o">.</span><span class="n">set_struct</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

                <span class="n">config</span> <span class="o">=</span> <span class="n">mridc</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">model_utils</span><span class="o">.</span><span class="n">maybe_update_config_version</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span> <span class="o">=</span> <span class="n">config</span>

            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;to_config_dict() can currently only return object._cfg but current object does not have it.&quot;</span>
        <span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>Returns object's configuration to config dictionary</p>
</div>


                            </div>
                </section>
                <section id="is_typecheck_enabled">
                            <div class="attr function"><a class="headerlink" href="#is_typecheck_enabled">#&nbsp;&nbsp</a>


            <span class="def">def</span>
            <span class="name">is_typecheck_enabled</span><span class="signature">()</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span><span class="k">def</span> <span class="nf">is_typecheck_enabled</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Getter method for typechecking state.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_TYPECHECK_ENABLED</span>
</pre></div>

        </details>

            <div class="docstring"><p>Getter method for typechecking state.</p>
</div>


                </section>
                <section id="typecheck">
                                <div class="attr class">
        <a class="headerlink" href="#typecheck">#&nbsp;&nbsp</a>


        <span class="def">class</span>
        <span class="name">typecheck</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span><span class="k">class</span> <span class="nc">typecheck</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Decorator to check the type of the input arguments.&quot;&quot;&quot;</span>

    <span class="k">class</span> <span class="nc">TypeState</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Placeholder to denote the default value of type information provided.</span>
<span class="sd">        If the constructor of this decorator is used to override the class level type definition,</span>
<span class="sd">        this enum value indicate that types will be overridden.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">UNINITIALIZED</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_types</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TypeState</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]]]</span> <span class="o">=</span> <span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span><span class="p">,</span>
        <span class="n">output_types</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TypeState</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]]]</span> <span class="o">=</span> <span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span><span class="p">,</span>
        <span class="n">ignore_collections</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A decorator which performs input-output neural type checks, and attaches</span>
<span class="sd">        neural types to the output of the function that it wraps.</span>
<span class="sd">        Requires that the class inherit from `mridc.core.Typing` in order to perform</span>
<span class="sd">        type checking, and will raise an error if that is not the case.</span>
<span class="sd">        # Usage (Class level type support)</span>
<span class="sd">        @typecheck()</span>
<span class="sd">        def fn(self, arg1, arg2, ...):</span>
<span class="sd">            ...</span>
<span class="sd">        # Usage (Function level type support)</span>
<span class="sd">        @typecheck(input_types=..., output_types=...)</span>
<span class="sd">        def fn(self, arg1, arg2, ...):</span>
<span class="sd">            ...</span>
<span class="sd">        Points to be noted:</span>
<span class="sd">        1) The brackets () in `@typecheck()` are necessary.</span>
<span class="sd">            You will encounter a TypeError: __init__() takes 1 positional argument but X</span>
<span class="sd">            were given without those brackets.</span>
<span class="sd">        2) The function can take any number of positional arguments during definition.</span>
<span class="sd">            When you call this function, all arguments must be passed using kwargs only.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_types</span> <span class="o">=</span> <span class="n">input_types</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_types</span> <span class="o">=</span> <span class="n">output_types</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_override</span> <span class="o">=</span> <span class="n">input_types</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_override</span> <span class="o">=</span> <span class="n">output_types</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_collections</span> <span class="o">=</span> <span class="n">ignore_collections</span>

    <span class="nd">@wrapt</span><span class="o">.</span><span class="n">decorator</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="n">is_typecheck_enabled</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wrapped</span><span class="p">,</span> <span class="n">instance</span><span class="p">:</span> <span class="n">Typing</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">instance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Only classes which inherit mridc.core.Typing can use this decorator !&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="n">Typing</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Only classes which inherit mridc.core.Typing can use this decorator !&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="s2">&quot;input_ports&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span> <span class="s2">&quot;output_ports&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Typing requires override of `input_types()` and `output_types()`, &quot;</span>
                <span class="s2">&quot;not `input_ports() and `output_ports()`&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Preserve type information</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_types</span> <span class="ow">is</span> <span class="n">typecheck</span><span class="o">.</span><span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_types</span> <span class="o">=</span> <span class="n">instance</span><span class="o">.</span><span class="n">input_types</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_types</span> <span class="ow">is</span> <span class="n">typecheck</span><span class="o">.</span><span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_types</span> <span class="o">=</span> <span class="n">instance</span><span class="o">.</span><span class="n">output_types</span>

        <span class="c1"># Resolve global type or local overridden type</span>
        <span class="n">input_types</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_types</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_override</span> <span class="k">else</span> <span class="n">instance</span><span class="o">.</span><span class="n">input_types</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_override</span><span class="p">:</span>
            <span class="n">output_types</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_types</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_types</span> <span class="o">=</span> <span class="n">instance</span><span class="o">.</span><span class="n">output_types</span>

        <span class="c1"># If types are not defined, skip type checks and just call the wrapped method</span>
        <span class="k">if</span> <span class="n">input_types</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">output_types</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Check that all arguments are kwargs</span>
        <span class="k">if</span> <span class="n">input_types</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;All arguments must be passed by kwargs only for typed methods&quot;</span><span class="p">)</span>

        <span class="c1"># Perform rudimentary input checks here</span>
        <span class="n">instance</span><span class="o">.</span><span class="n">_validate_input_types</span><span class="p">(</span><span class="n">input_types</span><span class="o">=</span><span class="n">input_types</span><span class="p">,</span> <span class="n">ignore_collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ignore_collections</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Call the method - this can be forward, or any other callable method</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">instance</span><span class="o">.</span><span class="n">_attach_and_validate_output_types</span><span class="p">(</span>
            <span class="n">output_types</span><span class="o">=</span><span class="n">output_types</span><span class="p">,</span> <span class="n">ignore_collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ignore_collections</span><span class="p">,</span> <span class="n">out_objects</span><span class="o">=</span><span class="n">outputs</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">set_typecheck_enabled</span><span class="p">(</span><span class="n">enabled</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the global typecheck flag.&quot;&quot;&quot;</span>
        <span class="k">global</span> <span class="n">_TYPECHECK_ENABLED</span>
        <span class="n">_TYPECHECK_ENABLED</span> <span class="o">=</span> <span class="n">enabled</span>

    <span class="nd">@staticmethod</span>
    <span class="nd">@contextmanager</span>
    <span class="k">def</span> <span class="nf">disable_checks</span><span class="p">():</span>
        <span class="sd">&quot;&quot;&quot;Temporarily disable type checks.&quot;&quot;&quot;</span>
        <span class="n">typecheck</span><span class="o">.</span><span class="n">set_typecheck_enabled</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">typecheck</span><span class="o">.</span><span class="n">set_typecheck_enabled</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>Decorator to check the type of the input arguments.</p>
</div>


                            <div id="typecheck.__init__" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#typecheck.__init__">#&nbsp;&nbsp</a>


            <span class="name">typecheck</span><span class="signature">(
    input_types: Union[<a href="#typecheck.TypeState">mridc.core.classes.common.typecheck.TypeState</a>, Dict[str, <a href="../neural_types/neural_type.html#NeuralType">mridc.core.neural_types.neural_type.NeuralType</a>], NoneType] = &lt;TypeState.UNINITIALIZED: 0&gt;,
    output_types: Union[<a href="#typecheck.TypeState">mridc.core.classes.common.typecheck.TypeState</a>, Dict[str, <a href="../neural_types/neural_type.html#NeuralType">mridc.core.neural_types.neural_type.NeuralType</a>], NoneType] = &lt;TypeState.UNINITIALIZED: 0&gt;,
    ignore_collections: bool = False
)</span>
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_types</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TypeState</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]]]</span> <span class="o">=</span> <span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span><span class="p">,</span>
        <span class="n">output_types</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TypeState</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]]]</span> <span class="o">=</span> <span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span><span class="p">,</span>
        <span class="n">ignore_collections</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A decorator which performs input-output neural type checks, and attaches</span>
<span class="sd">        neural types to the output of the function that it wraps.</span>
<span class="sd">        Requires that the class inherit from `mridc.core.Typing` in order to perform</span>
<span class="sd">        type checking, and will raise an error if that is not the case.</span>
<span class="sd">        # Usage (Class level type support)</span>
<span class="sd">        @typecheck()</span>
<span class="sd">        def fn(self, arg1, arg2, ...):</span>
<span class="sd">            ...</span>
<span class="sd">        # Usage (Function level type support)</span>
<span class="sd">        @typecheck(input_types=..., output_types=...)</span>
<span class="sd">        def fn(self, arg1, arg2, ...):</span>
<span class="sd">            ...</span>
<span class="sd">        Points to be noted:</span>
<span class="sd">        1) The brackets () in `@typecheck()` are necessary.</span>
<span class="sd">            You will encounter a TypeError: __init__() takes 1 positional argument but X</span>
<span class="sd">            were given without those brackets.</span>
<span class="sd">        2) The function can take any number of positional arguments during definition.</span>
<span class="sd">            When you call this function, all arguments must be passed using kwargs only.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_types</span> <span class="o">=</span> <span class="n">input_types</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_types</span> <span class="o">=</span> <span class="n">output_types</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_override</span> <span class="o">=</span> <span class="n">input_types</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_override</span> <span class="o">=</span> <span class="n">output_types</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">TypeState</span><span class="o">.</span><span class="n">UNINITIALIZED</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_collections</span> <span class="o">=</span> <span class="n">ignore_collections</span>
</pre></div>

        </details>

            <div class="docstring"><p>A decorator which performs input-output neural type checks, and attaches
neural types to the output of the function that it wraps.
Requires that the class inherit from <code><a href="../../core.html#Typing">mridc.core.Typing</a></code> in order to perform
type checking, and will raise an error if that is not the case.</p>

<h1 id="usage-class-level-type-support">Usage (Class level type support)</h1>

<p>@typecheck()
def fn(self, arg1, arg2, ...):
    ...</p>

<h1 id="usage-function-level-type-support">Usage (Function level type support)</h1>

<p>@typecheck(input_types=..., output_types=...)
def fn(self, arg1, arg2, ...):
    ...
Points to be noted:
1) The brackets () in <code>@typecheck()</code> are necessary.
    You will encounter a TypeError: __init__() takes 1 positional argument but X
    were given without those brackets.
2) The function can take any number of positional arguments during definition.
    When you call this function, all arguments must be passed using kwargs only.</p>
</div>


                            </div>
                            <div id="typecheck.set_typecheck_enabled" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#typecheck.set_typecheck_enabled">#&nbsp;&nbsp</a>

                <div class="decorator">@staticmethod</div>

            <span class="def">def</span>
            <span class="name">set_typecheck_enabled</span><span class="signature">(enabled: bool = True)</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">set_typecheck_enabled</span><span class="p">(</span><span class="n">enabled</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the global typecheck flag.&quot;&quot;&quot;</span>
        <span class="k">global</span> <span class="n">_TYPECHECK_ENABLED</span>
        <span class="n">_TYPECHECK_ENABLED</span> <span class="o">=</span> <span class="n">enabled</span>
</pre></div>

        </details>

            <div class="docstring"><p>Set the global typecheck flag.</p>
</div>


                            </div>
                            <div id="typecheck.disable_checks" class="classattr">
                                        <div class="attr function"><a class="headerlink" href="#typecheck.disable_checks">#&nbsp;&nbsp</a>

                <div class="decorator">@staticmethod</div>
        <div class="decorator">@contextmanager</div>

            <span class="def">def</span>
            <span class="name">disable_checks</span><span class="signature">()</span>:
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="nd">@staticmethod</span>
    <span class="nd">@contextmanager</span>
    <span class="k">def</span> <span class="nf">disable_checks</span><span class="p">():</span>
        <span class="sd">&quot;&quot;&quot;Temporarily disable type checks.&quot;&quot;&quot;</span>
        <span class="n">typecheck</span><span class="o">.</span><span class="n">set_typecheck_enabled</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">typecheck</span><span class="o">.</span><span class="n">set_typecheck_enabled</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

        </details>

            <div class="docstring"><p>Temporarily disable type checks.</p>
</div>


                            </div>
                </section>
                <section id="typecheck.TypeState">
                                <div class="attr class">
        <a class="headerlink" href="#typecheck.TypeState">#&nbsp;&nbsp</a>


        <span class="def">class</span>
        <span class="name">typecheck.TypeState</span><wbr>(<span class="base">enum.Enum</span>):
    </div>

            <details>
            <summary>View Source</summary>
            <div class="pdoc-code codehilite"><pre><span></span>    <span class="k">class</span> <span class="nc">TypeState</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Placeholder to denote the default value of type information provided.</span>
<span class="sd">        If the constructor of this decorator is used to override the class level type definition,</span>
<span class="sd">        this enum value indicate that types will be overridden.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">UNINITIALIZED</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>

        </details>

            <div class="docstring"><p>Placeholder to denote the default value of type information provided.
If the constructor of this decorator is used to override the class level type definition,
this enum value indicate that types will be overridden.</p>
</div>


                            <div id="typecheck.TypeState.UNINITIALIZED" class="classattr">
                                            <div class="attr variable"><a class="headerlink" href="#typecheck.TypeState.UNINITIALIZED">#&nbsp;&nbsp</a>

        <span class="name">UNINITIALIZED</span><span class="default_value"> = &lt;TypeState.UNINITIALIZED: 0&gt;</span>
    </div>




                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>enum.Enum</dt>
                                <dd id="typecheck.TypeState.name" class="variable">name</dd>
                <dd id="typecheck.TypeState.value" class="variable">value</dd>

            </div>
                                </dl>
                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../../../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../../../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.type) {
                    case "function":
                        heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span><span class="signature">${doc.signature}:</span>`;
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value">${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.type}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>
